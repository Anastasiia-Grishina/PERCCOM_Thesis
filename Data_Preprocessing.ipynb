{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from xlsxwriter.workbook import Workbook\n",
    "from xlsxwriter import Workbook\n",
    "import time\n",
    "Working_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_df = pd.read_excel( os.path.join( Working_dir, \"zabbix_v2_init.xlsx\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_df = pd.read_excel( os.path.join( Working_dir, \"jobs_v2_init.xlsx\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lsf_df = pd.read_excel( os.path.join( Working_dir, \"jobs_v2_py.xlsx\" ))\n",
    "# lsf_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Python date and time in comparable format (UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start_Timestamp (1h interval)' 'min_power' 'avg_power' 'max_power'\n",
      " 'measure time in seconds']\n",
      "['id' 'jobid' 'number of cores used' 'user name' 'queue name'\n",
      " 'directory of running executable' 'name of executable' 'job status'\n",
      " 'start unixtime' 'stop unixtime' 'numhost' 'Unnamed: 11' 'from']\n"
     ]
    }
   ],
   "source": [
    "print(zabbix_df.columns.values)\n",
    "print(lsf_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zabbix_df[\"date_py\"] = zabbix_df[\"Start_Timestamp (1h interval)\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).date())\n",
    "zabbix_df[\"time_py\"] = zabbix_df[\"Start_Timestamp (1h interval)\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).time())\n",
    "zabbix_df[\"timestamp_py\"] = zabbix_df[\"Start_Timestamp (1h interval)\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x))\n",
    "# lsf_df[\"start_date_py\"] = lsf_df[\"start unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).date())\n",
    "# lsf_df[\"start_time_py\"] = lsf_df[\"start unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).time())\n",
    "# lsf_df[\"end_date_py\"] = lsf_df[\"stop unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).date())\n",
    "# lsf_df[\"end_time_py\"] = lsf_df[\"stop unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).time())\n",
    "lsf_df[\"start_timestamp_py\"] = lsf_df[\"start unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x))\n",
    "lsf_df[\"stop_timestamp_py\"] = lsf_df[\"stop unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x))\n",
    "lsf_df['directory of running executable'] = lsf_df['directory of running executable'].fillna('')\n",
    "lsf_df['name of executable'] = lsf_df['name of executable'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_df['energy_avg (kWh)']=zabbix_df['avg_power'].copy()*zabbix_df['measure time in seconds'].copy()/60000.\n",
    "zabbix_df['energy_min (kWh)']=zabbix_df['min_power'].copy()*zabbix_df['measure time in seconds'].copy()/60000.\n",
    "zabbix_df['energy_max (kWh)']=zabbix_df['max_power'].copy()*zabbix_df['measure time in seconds'].copy()/60000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Timestamp (1h interval)</th>\n",
       "      <th>min_power</th>\n",
       "      <th>avg_power</th>\n",
       "      <th>max_power</th>\n",
       "      <th>measure time in seconds</th>\n",
       "      <th>date_py</th>\n",
       "      <th>time_py</th>\n",
       "      <th>timestamp_py</th>\n",
       "      <th>energy_avg (kWh)</th>\n",
       "      <th>energy_min (kWh)</th>\n",
       "      <th>energy_max (kWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1487505600</td>\n",
       "      <td>38600</td>\n",
       "      <td>40637</td>\n",
       "      <td>41500</td>\n",
       "      <td>60.00</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>2017-02-19 12:00:00</td>\n",
       "      <td>40.637000</td>\n",
       "      <td>38.600000</td>\n",
       "      <td>41.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1487509200</td>\n",
       "      <td>40010</td>\n",
       "      <td>40863</td>\n",
       "      <td>41530</td>\n",
       "      <td>60.00</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2017-02-19 13:00:00</td>\n",
       "      <td>40.863000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>41.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1487512800</td>\n",
       "      <td>37740</td>\n",
       "      <td>39971</td>\n",
       "      <td>41430</td>\n",
       "      <td>59.75</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>2017-02-19 14:00:00</td>\n",
       "      <td>39.804454</td>\n",
       "      <td>37.582750</td>\n",
       "      <td>41.257375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1487516400</td>\n",
       "      <td>36190</td>\n",
       "      <td>38517</td>\n",
       "      <td>39470</td>\n",
       "      <td>60.25</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>2017-02-19 15:00:00</td>\n",
       "      <td>38.677487</td>\n",
       "      <td>36.340792</td>\n",
       "      <td>39.634458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1487520000</td>\n",
       "      <td>38330</td>\n",
       "      <td>38735</td>\n",
       "      <td>39200</td>\n",
       "      <td>60.00</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>2017-02-19 16:00:00</td>\n",
       "      <td>38.735000</td>\n",
       "      <td>38.330000</td>\n",
       "      <td>39.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Timestamp (1h interval)  min_power  avg_power  max_power  \\\n",
       "0                     1487505600      38600      40637      41500   \n",
       "1                     1487509200      40010      40863      41530   \n",
       "2                     1487512800      37740      39971      41430   \n",
       "3                     1487516400      36190      38517      39470   \n",
       "4                     1487520000      38330      38735      39200   \n",
       "\n",
       "   measure time in seconds     date_py   time_py        timestamp_py  \\\n",
       "0                    60.00  2017-02-19  12:00:00 2017-02-19 12:00:00   \n",
       "1                    60.00  2017-02-19  13:00:00 2017-02-19 13:00:00   \n",
       "2                    59.75  2017-02-19  14:00:00 2017-02-19 14:00:00   \n",
       "3                    60.25  2017-02-19  15:00:00 2017-02-19 15:00:00   \n",
       "4                    60.00  2017-02-19  16:00:00 2017-02-19 16:00:00   \n",
       "\n",
       "   energy_avg (kWh)  energy_min (kWh)  energy_max (kWh)  \n",
       "0         40.637000         38.600000         41.500000  \n",
       "1         40.863000         40.010000         41.530000  \n",
       "2         39.804454         37.582750         41.257375  \n",
       "3         38.677487         36.340792         39.634458  \n",
       "4         38.735000         38.330000         39.200000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zabbix_df.drop( ['Start_Timestamp (1h interval)'], axis=1, inplace=True )\n",
    "zabbix_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All job ids are unique, they cannot be used as an identifier (it is checked for one month below)\n",
    "#### Different processes names can be identifiers, so we form the full names in lsf table \n",
    "Number of different job names (\"folder+name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_df['executable_full_name'] = lsf_df['directory of running executable'] + lsf_df['name of executable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique names of jobs in a year:  4614\n",
      "Jobs done in a year (including repetitions of the same jobs):  538837\n"
     ]
    }
   ],
   "source": [
    "print('Unique names of jobs in a year: ',len(lsf_df.executable_full_name.unique()))\n",
    "print('Jobs done in a year (including repetitions of the same jobs): ', lsf_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique user names in a year:  119\n"
     ]
    }
   ],
   "source": [
    "print('Unique user names in a year: ',len(lsf_df['user name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# l = list(lsf_df.executable_full_name)\n",
    "# dict((x,l.count(x)) for x in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobid</th>\n",
       "      <th>number of cores used</th>\n",
       "      <th>user name</th>\n",
       "      <th>queue name</th>\n",
       "      <th>job status</th>\n",
       "      <th>start unixtime</th>\n",
       "      <th>stop unixtime</th>\n",
       "      <th>start_timestamp_py</th>\n",
       "      <th>stop_timestamp_py</th>\n",
       "      <th>executable_full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>967084</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224146</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:42:26</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>967085</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224605</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:50:05</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>967086</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224688</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:51:28</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>967087</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224792</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:53:12</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967088</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224979</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:56:19</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    jobid  number of cores used user name  queue name job status  \\\n",
       "0  967084                    32     gusso  cresco4_h6       DONE   \n",
       "1  967085                    32     gusso  cresco4_h6       DONE   \n",
       "2  967086                    32     gusso  cresco4_h6       DONE   \n",
       "3  967087                    32     gusso  cresco4_h6       DONE   \n",
       "4  967088                    32     gusso  cresco4_h6       DONE   \n",
       "\n",
       "   start unixtime  stop unixtime  start_timestamp_py   stop_timestamp_py  \\\n",
       "0      1483190848     1483224146 2016-12-31 13:27:28 2016-12-31 22:42:26   \n",
       "1      1483190848     1483224605 2016-12-31 13:27:28 2016-12-31 22:50:05   \n",
       "2      1483190848     1483224688 2016-12-31 13:27:28 2016-12-31 22:51:28   \n",
       "3      1483190848     1483224792 2016-12-31 13:27:28 2016-12-31 22:53:12   \n",
       "4      1483190848     1483224979 2016-12-31 13:27:28 2016-12-31 22:56:19   \n",
       "\n",
       "                           executable_full_name  \n",
       "0  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  \n",
       "1  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  \n",
       "2  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  \n",
       "3  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  \n",
       "4  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf_df.drop( ['Unnamed: 11', 'from', 'id', 'numhost','directory of running executable','name of executable'], axis=1, inplace=True )\n",
    "# lsf_df.drop( [ 'start unixtime', 'stop unixtime'], axis=1, inplace=True )\n",
    "lsf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start_Timestamp (1h interval)' 'min_power' 'avg_power' 'max_power'\n",
      " 'measure time in seconds' 'date_py' 'time_py' 'timestamp_py'\n",
      " 'energy_avg (kWh)' 'energy_min (kWh)' 'energy_max (kWh)'] \n",
      "\n",
      "['jobid' 'number of cores used' 'user name' 'queue name' 'job status'\n",
      " 'start unixtime' 'stop unixtime' 'start_timestamp_py' 'stop_timestamp_py'\n",
      " 'executable_full_name']\n"
     ]
    }
   ],
   "source": [
    "print(zabbix_df.columns.values, \"\\n\")\n",
    "print(lsf_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8763, 11)\n",
      "(538837, 10)\n"
     ]
    }
   ],
   "source": [
    "print(zabbix_df.shape)\n",
    "print(lsf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_zabbix = pd.ExcelWriter( os.path.join( Working_dir, \"zabbix_v2_py.xlsx\"))\n",
    "zabbix_df.to_excel(excel_writer_zabbix)\n",
    "excel_writer_zabbix.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsf_df = lsf_df.sort_values('stop_timestamp_py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_writer_lsf = pd.ExcelWriter( os.path.join( Working_dir, \"lsf_v2_py.xlsx\" ))\n",
    "# excel_writer_lsf = pd.ExcelWriter( \"lsf_v2_py.xlsx\" )\n",
    "lsf_df.to_excel(excel_writer_lsf)\n",
    "excel_writer_lsf.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data for 19, February, 2017, 12:00 - 19, March, 2017, 12:00\n",
    "\n",
    "In lsf (jobs) file recordings starts from 2017-02-19 12:00:00, we need an interseciton of recordings from Lsf and Zabbix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find jobs that finished after 2017-02-19 12:00, started from this time, ended after and started before 2017-03-19 12:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_month_df = pd.DataFrame(columns = lsf_df.columns.values)\n",
    "i = 0\n",
    "for index, row in lsf_df.iterrows():\n",
    "#     start_datetime = datetime.datetime.utcfromtimestamp(row[\"start unixtime\"])\n",
    "    start_datetime = datetime.datetime.combine(row.start_date_py, \\\n",
    "                                           row.start_time_py )\n",
    "    end_datetime   = datetime.datetime.combine(row.end_date_py, \\\n",
    "                                           row.end_time_py )\n",
    "    #datetime.datetime.utcfromtimestamp(row[\"stop unixtime\"])\n",
    "        \n",
    "    moment_left = datetime.datetime(2017,2,19, 12,0)\n",
    "    moment_right = datetime.datetime(2017,3,19, 12,0)\n",
    "    \n",
    "    if ( (start_datetime >= moment_left  and end_datetime   <= moment_right) or\\\n",
    "         (start_datetime <= moment_left  and end_datetime   >= moment_left) or\\\n",
    "         (start_datetime <= moment_right and end_datetime  >= moment_right)):\n",
    "        lsf_month_df.loc[i] = row\n",
    "        i+=1\n",
    "    if (start_datetime >= datetime.datetime(2017,4,19, 0,0)):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_month_df = pd.DataFrame(columns = zabbix_df.columns.values)\n",
    "i = 0\n",
    "zabbix_timestamp = datetime.datetime.utcfromtimestamp(zabbix_df.loc[0,\\\n",
    "                                                                    \"Start_Timestamp (1h interval)\"])\n",
    "while (zabbix_timestamp < datetime.datetime(2017,3,19,12,0)):\n",
    "    zabbix_month_df.loc[i] = zabbix_df.loc[i]\n",
    "    i+=1\n",
    "    zabbix_timestamp = datetime.datetime.utcfromtimestamp(zabbix_df.loc[i,\\\n",
    "                                                                    \"Start_Timestamp (1h interval)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# excel_writer_zabbix = pd.ExcelWriter( Working_dir+'\\\\zabbix_month_py.xlsx')\n",
    "# zabbix_month_df.to_excel(excel_writer_zabbix)\n",
    "\n",
    "# excel_writer_lsf = pd.ExcelWriter( Working_dir+'\\\\lsf_month_py.xlsx')\n",
    "# lsf_month_df.to_excel(excel_writer_lsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zabbix_month_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsf_month_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_zabbix_month = pd.ExcelWriter( 'zabbix_month_py.xlsx')\n",
    "zabbix_month_df.to_excel(excel_writer_zabbix_month)\n",
    "\n",
    "excel_writer_lsf_month = pd.ExcelWriter( 'lsf_month_py.xlsx')\n",
    "lsf_month_df.to_excel(excel_writer_lsf_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job ids check up for one month. All job ids are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zabbix_month_df = pd.read_excel( os.path.join( Working_dir, \"zabbix_month_py.xlsx\" ) )\n",
    "lsf_month_df = pd.read_excel( os.path.join( Working_dir, \"lsf_month_py.xlsx\" ) )\n",
    "\n",
    "job_ids = list(lsf_month_df.jobid)\n",
    "job_ids_dict = dict((x,job_ids.count(x)) for x in job_ids)\n",
    "all(value == 1 for value in job_ids_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many processes running every second\n",
    "Processes are weighted during each second with the number of cores they require"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "Creating a dictionary\n",
    "\n",
    "Date + hour starting - key of an upper level\n",
    "\n",
    "Mins + sec - a key whithin an hour (on a lower level)\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will simply add 1 to each second when the app was running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_calc = zabbix_month_df.copy()\n",
    "lsf_calc = lsf_month_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_each_sec = { zabbix_calc.timestamp_py.iloc[0] : {}}\n",
    "print(type(apps_each_sec))\n",
    "for i in range (0, zabbix_calc.shape[0]):\n",
    "    \n",
    "    apps_each_sec[zabbix_calc.timestamp_py.iloc[i]] = {zabbix_calc.timestamp_py.iloc[i] \\\n",
    "                                                                  + datetime.timedelta(0,0) : 0}\n",
    "    for j in range (0,3600):\n",
    "        apps_each_sec[zabbix_calc.timestamp_py.iloc[i]][zabbix_calc.timestamp_py.iloc[i] \\\n",
    "                                                                  + datetime.timedelta(0,j)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will save the weighted number of tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps_weighted_each_sec = { zabbix_calc.timestamp_py.iloc[0] : {}}\n",
    "for i in range (0, zabbix_calc.shape[0]):\n",
    "    \n",
    "    apps_weighted_each_sec[zabbix_calc.timestamp_py.iloc[i]] = {zabbix_calc.timestamp_py.iloc[i] \\\n",
    "                                                                  + datetime.timedelta(0,0) : 0}\n",
    "    for j in range (0,3600):\n",
    "        apps_weighted_each_sec[zabbix_calc.timestamp_py.iloc[i]][zabbix_calc.timestamp_py.iloc[i] \\\n",
    "                                                                  + datetime.timedelta(0,j)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cores = lsf_month_df['number of cores used'].max()\n",
    "max_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_time = zabbix_calc.timestamp_py.iloc[0]\n",
    "max_time = zabbix_calc.timestamp_py.iloc[zabbix_calc.shape[0]-1] + datetime.timedelta(minutes = 59, seconds = 59)\n",
    "max_cores = lsf_calc['number of cores used'].max()\n",
    "\n",
    "for index, row in lsf_calc.iterrows(): #.iloc[:1]\n",
    "#     print(row)\n",
    "#     print(type(row))\n",
    "    start_time = datetime.datetime.combine(row.start_date_py, \\\n",
    "                                           row.start_time_py )\n",
    "    end_time = datetime.datetime.combine(row.end_date_py, \\\n",
    "                                           row.end_time_py )\n",
    "    cores = row['number of cores used']#/max_cores\n",
    "#     print('cores',cores)\n",
    "    t = start_time\n",
    "    \n",
    "    if min_time > start_time:\n",
    "        t = min_time\n",
    "    while t <= end_time and t <= max_time:\n",
    "        start_in_table = t\n",
    "        start_in_table = start_in_table.replace(minute=0, second=0)\n",
    "#         print('start_in_table', start_in_table)\n",
    "#         print('t', t)\n",
    "        apps_each_sec[start_in_table][t] +=1\n",
    "        apps_weighted_each_sec[start_in_table][t] += cores\n",
    "        t += datetime.timedelta(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('apps_each_sec_month.npy',apps_each_sec ) \n",
    "np.save('apps_weighted_each_sec_month.npy',apps_weighted_each_sec ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_calc = zabbix_df.copy()\n",
    "lsf_calc = lsf_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('apps_each_sec.npy',apps_each_sec ) \n",
    "np.save('apps_weighted_each_sec.npy',apps_weighted_each_sec ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_df = pd.DataFrame(columns = lsf_month_df.executable_full_name.unique(), index=zabbix_month_df.timestamp_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df = pd.DataFrame(columns = lsf_month_df.executable_full_name.unique(), index=zabbix_month_df.timestamp_py)\n",
    "\n",
    "min_time = zabbix_month_df.timestamp_py.iloc[0]\n",
    "max_time = zabbix_month_df.timestamp_py.iloc[zabbix_month_df.shape[0]-1] + datetime.timedelta(minutes = 59, seconds = 59)\n",
    "max_cores = lsf_month_df['number of cores used'].max()\n",
    "\n",
    "proc_df[:] = 0 \n",
    "i=0\n",
    "# iterate over jobs in lsf\n",
    "for index, line in lsf_month_df.iterrows():#.iloc[]\n",
    "#     print(line)\n",
    "    #i-line index\n",
    "    i+=1\n",
    "    job_name = line.executable_full_name\n",
    "    cores = line['number of cores used']\n",
    "    # start and end time in full date format \n",
    "    start_time = datetime.datetime.combine(line.start_date_py, \\\n",
    "                                           line.start_time_py )\n",
    "    end_time = datetime.datetime.combine(line.end_date_py, \\\n",
    "                                           line.end_time_py )\n",
    "    # t is our current position\n",
    "    t = start_time\n",
    "    # process length\n",
    "    length = end_time - start_time + datetime.timedelta(seconds=1)\n",
    "    # if a proces began before the first timestamp in zabbix\n",
    "    # decrease length and step onto the first timestamp in zabbix\n",
    "    if min_time > start_time:\n",
    "        t = min_time\n",
    "        length -= min_time - start_time\n",
    "    # while current position is not at the end time of a process or end of table\n",
    "    while t <= end_time and t <= max_time:\n",
    "        # find row name in table = even hour and next row name\n",
    "        start_in_table = t\n",
    "        start_in_table = start_in_table.replace(minute=0, second=0)\n",
    "        next_in_table = start_in_table + datetime.timedelta(hours=1)\n",
    "        \n",
    "        # if a process ends within this hour write its weight \n",
    "        # and put current position far to the right\n",
    "        if ( t + length < next_in_table ):\n",
    "#             print('length', length)\n",
    "            proc_df.loc[start_in_table,job_name] += (length.total_seconds()/3600)*(cores)#/max_cores)\n",
    "            t = next_in_table\n",
    "        else:\n",
    "            # if a process lasts longer than the current hour range\n",
    "            # add number of seconds which it runs during this hour\n",
    "            # decrease length of the process by the same mount\n",
    "            # write its weight to the matrix\n",
    "            to_add = next_in_table - t\n",
    "            length -= to_add\n",
    "            \n",
    "            proc_df.loc[start_in_table,job_name] += (to_add.total_seconds()/3600)*(cores)#/max_cores)\n",
    "            t += to_add\n",
    "    if (i % 1000 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_matrix = pd.ExcelWriter( 'proc_matrix_less_coeff_month.xlsx')\n",
    "proc_df.to_excel(excel_writer_matrix)\n",
    "excel_writer_matrix.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Add max & min equations\n",
    "- Find which sum of weights were max\n",
    "- Find what apps were active this hour (add new line in new DataFrame, then only matrices indices will merge) and this max second\n",
    "- Multiply weights by corresponding unknown variables == Put weights on the new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apps_each_sec = np.load('apps_each_sec.npy') \n",
    "apps_weighted_each_sec = np.load('apps_weighted_each_sec_month.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apps_each_sec = apps_each_sec[()]\n",
    "apps_weighted_each_sec = apps_weighted_each_sec[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_max_df = pd.DataFrame(columns = lsf_month_df.executable_full_name.unique())\n",
    "\n",
    "proc_min_df = pd.DataFrame(columns = lsf_month_df.executable_full_name.unique())\n",
    "\n",
    "# proc_max_df.loc[zabbix_month_df.timestamp_py.iloc[0]] = np.zeros(proc_max_df.shape[1])\n",
    "for k,row in apps_weighted_each_sec.items():\n",
    "    values_list = list(row.values())\n",
    "    proc_max_df.loc[ list(row.keys())[values_list.index(max(values_list))] ] = np.zeros(proc_max_df.shape[1])\n",
    "    proc_min_df.loc[ list(row.keys())[values_list.index(min(values_list))] ] = np.zeros(proc_min_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(proc_df.index.values[0]))#==datetime.datetime(year=2017,month=2, day=19,hour=12, second=2))\n",
    "print(datetime.datetime(year=2017,month=2, day=19,hour=12, second=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_time = zabbix_month_df.timestamp_py.iloc[0]\n",
    "max_time = zabbix_month_df.timestamp_py.iloc[zabbix_month_df.shape[0]-1] + datetime.timedelta(minutes = 59, seconds = 59)\n",
    "max_cores = lsf_month_df['number of cores used'].max()\n",
    "\n",
    "proc_max_df[:] = 0 \n",
    "proc_min_df[:] = 0 \n",
    "i=0\n",
    "# iterate over jobs in lsf\n",
    "for index, line in lsf_month_df.iterrows():#.iloc[]\n",
    "#     print(line)\n",
    "    #i-line index\n",
    "    i+=1\n",
    "    job_name = line.executable_full_name\n",
    "    cores = line['number of cores used']\n",
    "    # start and end time in full date format \n",
    "    start_time = datetime.datetime.combine(line.start_date_py, \\\n",
    "                                           line.start_time_py )\n",
    "    end_time = datetime.datetime.combine(line.end_date_py, \\\n",
    "                                           line.end_time_py )\n",
    "    for index, row in proc_max_df.iterrows():\n",
    "#         print(type(start_time.timestamp()))\n",
    "#         print(type(index.timestamp()))\n",
    "        if ((index.timestamp() >= start_time.timestamp()) & (index.timestamp() <= end_time.timestamp())):\n",
    "#             print(start_time, index, end_time, '\\n')\n",
    "            proc_max_df.loc[index,job_name] += cores#/max_cores\n",
    "        if (index.timestamp() > end_time.timestamp()):\n",
    "            break\n",
    "            \n",
    "    for index, row in proc_min_df.iterrows():\n",
    "#         print(type(start_time.timestamp()))\n",
    "#         print(type(index.timestamp()))\n",
    "        if ((index.timestamp() >= start_time.timestamp()) & (index.timestamp() <= end_time.timestamp())):\n",
    "#             print(start_time, index, end_time, '\\n')\n",
    "            proc_min_df.loc[index,job_name] += cores#/max_cores\n",
    "        if (index.timestamp() > end_time.timestamp()):\n",
    "            break\n",
    "#     print('after break in iterrows')\n",
    "    if (i % 1000 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_matrix_max = pd.ExcelWriter( os.path.join( Working_dir, 'proc_max_matrix.xlsx' ))\n",
    "proc_max_df.to_excel(excel_writer_matrix_max)\n",
    "excel_writer_matrix_max.save()\n",
    "\n",
    "excel_writer_matrix_min = pd.ExcelWriter( os.path.join( Working_dir, 'proc_min_matrix.xlsx' ))\n",
    "proc_min_df.to_excel(excel_writer_matrix_min)\n",
    "excel_writer_matrix_min.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
