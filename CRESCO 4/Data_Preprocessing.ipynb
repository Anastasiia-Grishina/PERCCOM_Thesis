{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from xlsxwriter.workbook import Workbook\n",
    "from xlsxwriter import Workbook\n",
    "import time\n",
    "Working_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_df = pd.read_excel( os.path.join( Working_dir, \"zabbix_v2_init.xlsx\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_df = pd.read_excel( os.path.join( Working_dir, \"jobs_v2_init.xlsx\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lsf_df = pd.read_excel( os.path.join( Working_dir, \"jobs_v2_py.xlsx\" ))\n",
    "# lsf_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Python date and time in comparable format (UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start_Timestamp (1h interval)' 'min_power' 'avg_power' 'max_power'\n",
      " 'measure time in seconds']\n",
      "['id' 'jobid' 'number of cores used' 'user name' 'queue name'\n",
      " 'directory of running executable' 'name of executable' 'job status'\n",
      " 'start unixtime' 'stop unixtime' 'numhost' 'Unnamed: 11' 'from']\n"
     ]
    }
   ],
   "source": [
    "print(zabbix_df.columns.values)\n",
    "print(lsf_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_df[\"date_py\"] = zabbix_df[\"Start_Timestamp (1h interval)\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).date())\n",
    "zabbix_df[\"time_py\"] = zabbix_df[\"Start_Timestamp (1h interval)\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).time())\n",
    "zabbix_df[\"timestamp_py\"] = zabbix_df[\"Start_Timestamp (1h interval)\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x))\n",
    "# lsf_df[\"start_date_py\"] = lsf_df[\"start unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).date())\n",
    "# lsf_df[\"start_time_py\"] = lsf_df[\"start unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).time())\n",
    "# lsf_df[\"end_date_py\"] = lsf_df[\"stop unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).date())\n",
    "# lsf_df[\"end_time_py\"] = lsf_df[\"stop unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).time())\n",
    "lsf_df[\"start_timestamp_py\"] = lsf_df[\"start unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x))\n",
    "lsf_df[\"stop_timestamp_py\"] = lsf_df[\"stop unixtime\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x))\n",
    "lsf_df['directory of running executable'] = lsf_df['directory of running executable'].fillna('')\n",
    "lsf_df['name of executable'] = lsf_df['name of executable'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_df['energy_avg (kWh)']=zabbix_df['avg_power'].copy()*zabbix_df['measure time in seconds'].copy()/60000.\n",
    "zabbix_df['energy_min (kWh)']=zabbix_df['min_power'].copy()*zabbix_df['measure time in seconds'].copy()/60000.\n",
    "zabbix_df['energy_max (kWh)']=zabbix_df['max_power'].copy()*zabbix_df['measure time in seconds'].copy()/60000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Timestamp (1h interval)</th>\n",
       "      <th>min_power</th>\n",
       "      <th>avg_power</th>\n",
       "      <th>max_power</th>\n",
       "      <th>measure time in seconds</th>\n",
       "      <th>date_py</th>\n",
       "      <th>time_py</th>\n",
       "      <th>timestamp_py</th>\n",
       "      <th>energy_avg (kWh)</th>\n",
       "      <th>energy_min (kWh)</th>\n",
       "      <th>energy_max (kWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1487505600</td>\n",
       "      <td>38600</td>\n",
       "      <td>40637</td>\n",
       "      <td>41500</td>\n",
       "      <td>60.00</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>2017-02-19 12:00:00</td>\n",
       "      <td>40.637000</td>\n",
       "      <td>38.600000</td>\n",
       "      <td>41.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1487509200</td>\n",
       "      <td>40010</td>\n",
       "      <td>40863</td>\n",
       "      <td>41530</td>\n",
       "      <td>60.00</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2017-02-19 13:00:00</td>\n",
       "      <td>40.863000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>41.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1487512800</td>\n",
       "      <td>37740</td>\n",
       "      <td>39971</td>\n",
       "      <td>41430</td>\n",
       "      <td>59.75</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>2017-02-19 14:00:00</td>\n",
       "      <td>39.804454</td>\n",
       "      <td>37.582750</td>\n",
       "      <td>41.257375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1487516400</td>\n",
       "      <td>36190</td>\n",
       "      <td>38517</td>\n",
       "      <td>39470</td>\n",
       "      <td>60.25</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>2017-02-19 15:00:00</td>\n",
       "      <td>38.677487</td>\n",
       "      <td>36.340792</td>\n",
       "      <td>39.634458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1487520000</td>\n",
       "      <td>38330</td>\n",
       "      <td>38735</td>\n",
       "      <td>39200</td>\n",
       "      <td>60.00</td>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>2017-02-19 16:00:00</td>\n",
       "      <td>38.735000</td>\n",
       "      <td>38.330000</td>\n",
       "      <td>39.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Timestamp (1h interval)  min_power  avg_power  max_power  \\\n",
       "0                     1487505600      38600      40637      41500   \n",
       "1                     1487509200      40010      40863      41530   \n",
       "2                     1487512800      37740      39971      41430   \n",
       "3                     1487516400      36190      38517      39470   \n",
       "4                     1487520000      38330      38735      39200   \n",
       "\n",
       "   measure time in seconds     date_py   time_py        timestamp_py  \\\n",
       "0                    60.00  2017-02-19  12:00:00 2017-02-19 12:00:00   \n",
       "1                    60.00  2017-02-19  13:00:00 2017-02-19 13:00:00   \n",
       "2                    59.75  2017-02-19  14:00:00 2017-02-19 14:00:00   \n",
       "3                    60.25  2017-02-19  15:00:00 2017-02-19 15:00:00   \n",
       "4                    60.00  2017-02-19  16:00:00 2017-02-19 16:00:00   \n",
       "\n",
       "   energy_avg (kWh)  energy_min (kWh)  energy_max (kWh)  \n",
       "0         40.637000         38.600000         41.500000  \n",
       "1         40.863000         40.010000         41.530000  \n",
       "2         39.804454         37.582750         41.257375  \n",
       "3         38.677487         36.340792         39.634458  \n",
       "4         38.735000         38.330000         39.200000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zabbix_df.drop( ['Start_Timestamp (1h interval)'], axis=1, inplace=True )\n",
    "zabbix_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All job ids are unique, they cannot be used as an identifier (it is checked for one month below)\n",
    "#### Different processes names can be identifiers, so we form the full names in lsf table \n",
    "Number of different job names (\"folder+name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_df['executable_full_name'] = lsf_df['directory of running executable'] + lsf_df['name of executable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique names of jobs in a year:  4614\n",
      "Jobs done in a year (including repetitions of the same jobs):  538837\n"
     ]
    }
   ],
   "source": [
    "print('Unique names of jobs in a year: ',len(lsf_df.executable_full_name.unique()))\n",
    "print('Jobs done in a year (including repetitions of the same jobs): ', lsf_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique user names in a year:  119\n"
     ]
    }
   ],
   "source": [
    "print('Unique user names in a year: ',len(lsf_df['user name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# l = list(lsf_df.executable_full_name)\n",
    "# dict((x,l.count(x)) for x in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobid</th>\n",
       "      <th>number of cores used</th>\n",
       "      <th>user name</th>\n",
       "      <th>queue name</th>\n",
       "      <th>job status</th>\n",
       "      <th>start unixtime</th>\n",
       "      <th>stop unixtime</th>\n",
       "      <th>start_timestamp_py</th>\n",
       "      <th>stop_timestamp_py</th>\n",
       "      <th>executable_full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>967084</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224146</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:42:26</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>967085</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224605</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:50:05</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>967086</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224688</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:51:28</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>967087</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224792</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:53:12</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967088</td>\n",
       "      <td>32</td>\n",
       "      <td>gusso</td>\n",
       "      <td>cresco4_h6</td>\n",
       "      <td>DONE</td>\n",
       "      <td>1483190848</td>\n",
       "      <td>1483224979</td>\n",
       "      <td>2016-12-31 13:27:28</td>\n",
       "      <td>2016-12-31 22:56:19</td>\n",
       "      <td>PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    jobid  number of cores used user name  queue name job status  \\\n",
       "0  967084                    32     gusso  cresco4_h6       DONE   \n",
       "1  967085                    32     gusso  cresco4_h6       DONE   \n",
       "2  967086                    32     gusso  cresco4_h6       DONE   \n",
       "3  967087                    32     gusso  cresco4_h6       DONE   \n",
       "4  967088                    32     gusso  cresco4_h6       DONE   \n",
       "\n",
       "   start unixtime  stop unixtime  start_timestamp_py   stop_timestamp_py  \\\n",
       "0      1483190848     1483224146 2016-12-31 13:27:28 2016-12-31 22:42:26   \n",
       "1      1483190848     1483224605 2016-12-31 13:27:28 2016-12-31 22:50:05   \n",
       "2      1483190848     1483224688 2016-12-31 13:27:28 2016-12-31 22:51:28   \n",
       "3      1483190848     1483224792 2016-12-31 13:27:28 2016-12-31 22:53:12   \n",
       "4      1483190848     1483224979 2016-12-31 13:27:28 2016-12-31 22:56:19   \n",
       "\n",
       "                           executable_full_name  \n",
       "0  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  \n",
       "1  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  \n",
       "2  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  \n",
       "3  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  \n",
       "4  PFS/porq1_1M/SiH/Grossman/cp2kcp2k_launch.sh  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf_df.drop( ['Unnamed: 11', 'from', 'id', 'numhost','directory of running executable','name of executable'], axis=1, inplace=True )\n",
    "# lsf_df.drop( [ 'start unixtime', 'stop unixtime'], axis=1, inplace=True )\n",
    "lsf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start_Timestamp (1h interval)' 'min_power' 'avg_power' 'max_power'\n",
      " 'measure time in seconds' 'date_py' 'time_py' 'timestamp_py'\n",
      " 'energy_avg (kWh)' 'energy_min (kWh)' 'energy_max (kWh)'] \n",
      "\n",
      "['jobid' 'number of cores used' 'user name' 'queue name' 'job status'\n",
      " 'start unixtime' 'stop unixtime' 'start_timestamp_py' 'stop_timestamp_py'\n",
      " 'executable_full_name']\n"
     ]
    }
   ],
   "source": [
    "print(zabbix_df.columns.values, \"\\n\")\n",
    "print(lsf_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8763, 11)\n",
      "(538837, 10)\n"
     ]
    }
   ],
   "source": [
    "print(zabbix_df.shape)\n",
    "print(lsf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_zabbix = pd.ExcelWriter( os.path.join( Working_dir, \"zabbix_v2_py.xlsx\"))\n",
    "zabbix_df.to_excel(excel_writer_zabbix)\n",
    "excel_writer_zabbix.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_df = lsf_df.sort_values('stop_timestamp_py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_lsf = pd.ExcelWriter( os.path.join( Working_dir, \"lsf_v2_py.xlsx\" ))\n",
    "# excel_writer_lsf = pd.ExcelWriter( \"lsf_v2_py.xlsx\" )\n",
    "lsf_df.to_excel(excel_writer_lsf)\n",
    "excel_writer_lsf.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data for 19, February, 2017, 12:00 - 19, March, 2017, 12:00\n",
    "\n",
    "In lsf (jobs) file recordings starts from 2017-02-19 12:00:00, we need an interseciton of recordings from Lsf and Zabbix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find jobs that finished after 2017-02-19 12:00, started from this time, ended after and started before 2017-03-19 12:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_month_df = pd.DataFrame(columns = lsf_df.columns.values)\n",
    "i = 0\n",
    "for index, row in lsf_df.iterrows():\n",
    "#     start_datetime = datetime.datetime.utcfromtimestamp(row[\"start unixtime\"])\n",
    "    start_datetime = datetime.datetime.combine(row.start_date_py, \\\n",
    "                                           row.start_time_py )\n",
    "    end_datetime   = datetime.datetime.combine(row.end_date_py, \\\n",
    "                                           row.end_time_py )\n",
    "    #datetime.datetime.utcfromtimestamp(row[\"stop unixtime\"])\n",
    "        \n",
    "    moment_left = datetime.datetime(2017,2,19, 12,0)\n",
    "    moment_right = datetime.datetime(2017,3,19, 12,0)\n",
    "    \n",
    "    if ( (start_datetime >= moment_left  and end_datetime   <= moment_right) or\\\n",
    "         (start_datetime <= moment_left  and end_datetime   >= moment_left) or\\\n",
    "         (start_datetime <= moment_right and end_datetime  >= moment_right)):\n",
    "        lsf_month_df.loc[i] = row\n",
    "        i+=1\n",
    "    if (start_datetime >= datetime.datetime(2017,4,19, 0,0)):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_month_df = pd.DataFrame(columns = zabbix_df.columns.values)\n",
    "i = 0\n",
    "zabbix_timestamp = datetime.datetime.utcfromtimestamp(zabbix_df.loc[0,\\\n",
    "                                                                    \"Start_Timestamp (1h interval)\"])\n",
    "while (zabbix_timestamp < datetime.datetime(2017,3,19,12,0)):\n",
    "    zabbix_month_df.loc[i] = zabbix_df.loc[i]\n",
    "    i+=1\n",
    "    zabbix_timestamp = datetime.datetime.utcfromtimestamp(zabbix_df.loc[i,\\\n",
    "                                                                    \"Start_Timestamp (1h interval)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# excel_writer_zabbix = pd.ExcelWriter( Working_dir+'\\\\zabbix_month_py.xlsx')\n",
    "# zabbix_month_df.to_excel(excel_writer_zabbix)\n",
    "\n",
    "# excel_writer_lsf = pd.ExcelWriter( Working_dir+'\\\\lsf_month_py.xlsx')\n",
    "# lsf_month_df.to_excel(excel_writer_lsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_month_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_month_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_zabbix_month = pd.ExcelWriter( 'zabbix_month_py.xlsx')\n",
    "zabbix_month_df.to_excel(excel_writer_zabbix_month)\n",
    "\n",
    "excel_writer_lsf_month = pd.ExcelWriter( 'lsf_month_py.xlsx')\n",
    "lsf_month_df.to_excel(excel_writer_lsf_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job ids check up for one month. All job ids are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_month_df = pd.read_excel( os.path.join( Working_dir, \"zabbix_month_py.xlsx\" ) )\n",
    "lsf_month_df = pd.read_excel( os.path.join( Working_dir, \"lsf_month_py.xlsx\" ) )\n",
    "\n",
    "job_ids = list(lsf_month_df.jobid)\n",
    "job_ids_dict = dict((x,job_ids.count(x)) for x in job_ids)\n",
    "all(value == 1 for value in job_ids_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many processes running every second\n",
    "Processes are weighted during each second with the number of cores they require"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "Creating a dictionary\n",
    "\n",
    "Date + hour starting - key of an upper level\n",
    "\n",
    "Mins + sec - a key whithin an hour (on a lower level)\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will simply add 1 to each second when the app was running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_calc = zabbix_month_df.copy()\n",
    "lsf_calc = lsf_month_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps_each_sec = { zabbix_calc.timestamp_py.iloc[0] : {}}\n",
    "print(type(apps_each_sec))\n",
    "for i in range (0, zabbix_calc.shape[0]):\n",
    "    \n",
    "    apps_each_sec[zabbix_calc.timestamp_py.iloc[i]] = {zabbix_calc.timestamp_py.iloc[i] \\\n",
    "                                                                  + datetime.timedelta(0,0) : 0}\n",
    "    for j in range (0,3600):\n",
    "        apps_each_sec[zabbix_calc.timestamp_py.iloc[i]][zabbix_calc.timestamp_py.iloc[i] \\\n",
    "                                                                  + datetime.timedelta(0,j)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will save the weighted number of tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps_weighted_each_sec = { zabbix_calc.timestamp_py.iloc[0] : {}}\n",
    "for i in range (0, zabbix_calc.shape[0]):\n",
    "    \n",
    "    apps_weighted_each_sec[zabbix_calc.timestamp_py.iloc[i]] = {zabbix_calc.timestamp_py.iloc[i] \\\n",
    "                                                                  + datetime.timedelta(0,0) : 0}\n",
    "    for j in range (0,3600):\n",
    "        apps_weighted_each_sec[zabbix_calc.timestamp_py.iloc[i]][zabbix_calc.timestamp_py.iloc[i] \\\n",
    "                                                                  + datetime.timedelta(0,j)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_cores = lsf_month_df['number of cores used'].max()\n",
    "max_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_time = zabbix_calc.timestamp_py.iloc[0]\n",
    "max_time = zabbix_calc.timestamp_py.iloc[zabbix_calc.shape[0]-1] + datetime.timedelta(minutes = 59, seconds = 59)\n",
    "max_cores = lsf_calc['number of cores used'].max()\n",
    "\n",
    "for index, row in lsf_calc.iterrows(): #.iloc[:1]\n",
    "#     print(row)\n",
    "#     print(type(row))\n",
    "    start_time = datetime.datetime.combine(row.start_date_py, \\\n",
    "                                           row.start_time_py )\n",
    "    end_time = datetime.datetime.combine(row.end_date_py, \\\n",
    "                                           row.end_time_py )\n",
    "    cores = row['number of cores used']#/max_cores\n",
    "#     print('cores',cores)\n",
    "    t = start_time\n",
    "    \n",
    "    if min_time > start_time:\n",
    "        t = min_time\n",
    "    while t <= end_time and t <= max_time:\n",
    "        start_in_table = t\n",
    "        start_in_table = start_in_table.replace(minute=0, second=0)\n",
    "#         print('start_in_table', start_in_table)\n",
    "#         print('t', t)\n",
    "        apps_each_sec[start_in_table][t] +=1\n",
    "        apps_weighted_each_sec[start_in_table][t] += cores\n",
    "        t += datetime.timedelta(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('apps_each_sec_month.npy',apps_each_sec ) \n",
    "np.save('apps_weighted_each_sec_month.npy',apps_weighted_each_sec ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_calc = zabbix_df.copy()\n",
    "lsf_calc = lsf_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('apps_each_sec.npy',apps_each_sec ) \n",
    "np.save('apps_weighted_each_sec.npy',apps_weighted_each_sec ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_df = pd.DataFrame(columns = lsf_month_df.executable_full_name.unique(), index=zabbix_month_df.timestamp_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_df = pd.DataFrame(columns = lsf_month_df.executable_full_name.unique(), index=zabbix_month_df.timestamp_py)\n",
    "\n",
    "min_time = zabbix_month_df.timestamp_py.iloc[0]\n",
    "max_time = zabbix_month_df.timestamp_py.iloc[zabbix_month_df.shape[0]-1] + datetime.timedelta(minutes = 59, seconds = 59)\n",
    "max_cores = lsf_month_df['number of cores used'].max()\n",
    "\n",
    "proc_df[:] = 0 \n",
    "i=0\n",
    "# iterate over jobs in lsf\n",
    "for index, line in lsf_month_df.iterrows():#.iloc[]\n",
    "#     print(line)\n",
    "    #i-line index\n",
    "    i+=1\n",
    "    job_name = line.executable_full_name\n",
    "    cores = line['number of cores used']\n",
    "    # start and end time in full date format \n",
    "    start_time = datetime.datetime.combine(line.start_date_py, \\\n",
    "                                           line.start_time_py )\n",
    "    end_time = datetime.datetime.combine(line.end_date_py, \\\n",
    "                                           line.end_time_py )\n",
    "    # t is our current position\n",
    "    t = start_time\n",
    "    # process length\n",
    "    length = end_time - start_time + datetime.timedelta(seconds=1)\n",
    "    # if a proces began before the first timestamp in zabbix\n",
    "    # decrease length and step onto the first timestamp in zabbix\n",
    "    if min_time > start_time:\n",
    "        t = min_time\n",
    "        length -= min_time - start_time\n",
    "    # while current position is not at the end time of a process or end of table\n",
    "    while t <= end_time and t <= max_time:\n",
    "        # find row name in table = even hour and next row name\n",
    "        start_in_table = t\n",
    "        start_in_table = start_in_table.replace(minute=0, second=0)\n",
    "        next_in_table = start_in_table + datetime.timedelta(hours=1)\n",
    "        \n",
    "        # if a process ends within this hour write its weight \n",
    "        # and put current position far to the right\n",
    "        if ( t + length < next_in_table ):\n",
    "#             print('length', length)\n",
    "            proc_df.loc[start_in_table,job_name] += (length.total_seconds()/3600)*(cores)#/max_cores)\n",
    "            t = next_in_table\n",
    "        else:\n",
    "            # if a process lasts longer than the current hour range\n",
    "            # add number of seconds which it runs during this hour\n",
    "            # decrease length of the process by the same mount\n",
    "            # write its weight to the matrix\n",
    "            to_add = next_in_table - t\n",
    "            length -= to_add\n",
    "            \n",
    "            proc_df.loc[start_in_table,job_name] += (to_add.total_seconds()/3600)*(cores)#/max_cores)\n",
    "            t += to_add\n",
    "    if (i % 1000 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_matrix = pd.ExcelWriter( 'proc_matrix_less_coeff_month.xlsx')\n",
    "proc_df.to_excel(excel_writer_matrix)\n",
    "excel_writer_matrix.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Add max & min equations\n",
    "- Find which sum of weights were max\n",
    "- Find what apps were active this hour (add new line in new DataFrame, then only matrices indices will merge) and this max second\n",
    "- Multiply weights by corresponding unknown variables == Put weights on the new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apps_each_sec = np.load('apps_each_sec.npy') \n",
    "apps_weighted_each_sec = np.load('apps_weighted_each_sec_month.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apps_each_sec = apps_each_sec[()]\n",
    "apps_weighted_each_sec = apps_weighted_each_sec[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_max_df = pd.DataFrame(columns = lsf_month_df.executable_full_name.unique())\n",
    "\n",
    "proc_min_df = pd.DataFrame(columns = lsf_month_df.executable_full_name.unique())\n",
    "\n",
    "# proc_max_df.loc[zabbix_month_df.timestamp_py.iloc[0]] = np.zeros(proc_max_df.shape[1])\n",
    "for k,row in apps_weighted_each_sec.items():\n",
    "    values_list = list(row.values())\n",
    "    proc_max_df.loc[ list(row.keys())[values_list.index(max(values_list))] ] = np.zeros(proc_max_df.shape[1])\n",
    "    proc_min_df.loc[ list(row.keys())[values_list.index(min(values_list))] ] = np.zeros(proc_min_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(proc_df.index.values[0]))#==datetime.datetime(year=2017,month=2, day=19,hour=12, second=2))\n",
    "print(datetime.datetime(year=2017,month=2, day=19,hour=12, second=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_time = zabbix_month_df.timestamp_py.iloc[0]\n",
    "max_time = zabbix_month_df.timestamp_py.iloc[zabbix_month_df.shape[0]-1] + datetime.timedelta(minutes = 59, seconds = 59)\n",
    "max_cores = lsf_month_df['number of cores used'].max()\n",
    "\n",
    "proc_max_df[:] = 0 \n",
    "proc_min_df[:] = 0 \n",
    "i=0\n",
    "# iterate over jobs in lsf\n",
    "for index, line in lsf_month_df.iterrows():#.iloc[]\n",
    "#     print(line)\n",
    "    #i-line index\n",
    "    i+=1\n",
    "    job_name = line.executable_full_name\n",
    "    cores = line['number of cores used']\n",
    "    # start and end time in full date format \n",
    "    start_time = datetime.datetime.combine(line.start_date_py, \\\n",
    "                                           line.start_time_py )\n",
    "    end_time = datetime.datetime.combine(line.end_date_py, \\\n",
    "                                           line.end_time_py )\n",
    "    for index, row in proc_max_df.iterrows():\n",
    "#         print(type(start_time.timestamp()))\n",
    "#         print(type(index.timestamp()))\n",
    "        if ((index.timestamp() >= start_time.timestamp()) & (index.timestamp() <= end_time.timestamp())):\n",
    "#             print(start_time, index, end_time, '\\n')\n",
    "            proc_max_df.loc[index,job_name] += cores#/max_cores\n",
    "        if (index.timestamp() > end_time.timestamp()):\n",
    "            break\n",
    "            \n",
    "    for index, row in proc_min_df.iterrows():\n",
    "#         print(type(start_time.timestamp()))\n",
    "#         print(type(index.timestamp()))\n",
    "        if ((index.timestamp() >= start_time.timestamp()) & (index.timestamp() <= end_time.timestamp())):\n",
    "#             print(start_time, index, end_time, '\\n')\n",
    "            proc_min_df.loc[index,job_name] += cores#/max_cores\n",
    "        if (index.timestamp() > end_time.timestamp()):\n",
    "            break\n",
    "#     print('after break in iterrows')\n",
    "    if (i % 1000 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_writer_matrix_max = pd.ExcelWriter( os.path.join( Working_dir, 'proc_max_matrix.xlsx' ))\n",
    "proc_max_df.to_excel(excel_writer_matrix_max)\n",
    "excel_writer_matrix_max.save()\n",
    "\n",
    "excel_writer_matrix_min = pd.ExcelWriter( os.path.join( Working_dir, 'proc_min_matrix.xlsx' ))\n",
    "proc_min_df.to_excel(excel_writer_matrix_min)\n",
    "excel_writer_matrix_min.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----\n",
    "## Regrouped lsf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_gr_df = pd.read_excel( os.path.join( Working_dir, \"Improved_lsf_for_jobs_running_less_than_30.xlsx\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jobid', 'inizio', 'fine', 'durata in sec', 'numcores', 'user',\n",
       "       'queue', 'directory', 'executable', 'jobstatus', 'numhost'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf_gr_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_gr_df[\"start_timestamp_py\"] = lsf_gr_df[\"inizio\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x))\n",
    "lsf_gr_df[\"stop_timestamp_py\"] = lsf_gr_df[\"fine\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x))\n",
    "lsf_gr_df[\"duration_py\"] = (lsf_gr_df[\"stop_timestamp_py\"] - lsf_gr_df[\"start_timestamp_py\"]).apply(lambda x: x.total_seconds())\n",
    "lsf_gr_df['directory'] = lsf_gr_df['directory'].fillna('')\n",
    "lsf_gr_df['executable'] = lsf_gr_df['executable'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether difference between stop and start time is exactly \"durata\"\n",
    "python checkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502272, 14)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf_gr_df[lsf_gr_df[\"duration_py\"] == lsf_gr_df[\"durata in sec\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69199, 14)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf_gr_df[lsf_gr_df[\"duration_py\"] != lsf_gr_df[\"durata in sec\"]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unix checkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 14)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf_gr_df[(lsf_gr_df[\"fine\"] - lsf_gr_df[\"inizio\"]) != lsf_gr_df[\"durata in sec\"]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will keep duration_py = durata in sec, since unix time difference is more precise than python datetime difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_gr_df[\"duration_py\"] = lsf_gr_df[\"durata in sec\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobid           502922\n",
      "executable    03:00:00\n",
      "Name: 467782, dtype: object\n",
      "<class 'datetime.time'>\n",
      "\n",
      "\n",
      "jobid           502923\n",
      "executable    03:00:00\n",
      "Name: 467783, dtype: object\n",
      "<class 'datetime.time'>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(lsf_gr_df.shape[0]):\n",
    "    a = lsf_gr_df.loc[i, 'executable']\n",
    "    if type(a)!=str and type(a) != int:\n",
    "        print(lsf_gr_df.loc[i, ['jobid', 'executable']])\n",
    "        print(type(a))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create full path name for the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_gr_df[\"executable_full_name\"] = lsf_gr_df[\"directory\"].apply( lambda x: str(x) if type(x) == int else x ) \\\n",
    "    + lsf_gr_df[\"executable\"].apply( lambda x: str(x) if type(x) == int else \\\n",
    "                                    (x.strftime('%H-%M-%S') if type(x)==datetime.time else x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_gr_df.drop( ['durata in sec'], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_gr_df = lsf_gr_df.sort_values('stop_timestamp_py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobid</th>\n",
       "      <th>inizio</th>\n",
       "      <th>fine</th>\n",
       "      <th>numcores</th>\n",
       "      <th>user</th>\n",
       "      <th>queue</th>\n",
       "      <th>directory</th>\n",
       "      <th>executable</th>\n",
       "      <th>jobstatus</th>\n",
       "      <th>numhost</th>\n",
       "      <th>start_timestamp_py</th>\n",
       "      <th>stop_timestamp_py</th>\n",
       "      <th>duration_py</th>\n",
       "      <th>executable_full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544642</th>\n",
       "      <td>964821</td>\n",
       "      <td>1482748132</td>\n",
       "      <td>1482748136</td>\n",
       "      <td>64</td>\n",
       "      <td>grena</td>\n",
       "      <td>cresco3_h144</td>\n",
       "      <td>PFS/porq1_1M/Al_cluster</td>\n",
       "      <td>qe5.0.3_par</td>\n",
       "      <td>DONE</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-12-26 10:28:52</td>\n",
       "      <td>2016-12-26 10:28:56</td>\n",
       "      <td>4</td>\n",
       "      <td>PFS/porq1_1M/Al_clusterqe5.0.3_par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544643</th>\n",
       "      <td>964823</td>\n",
       "      <td>1482748161</td>\n",
       "      <td>1482748168</td>\n",
       "      <td>64</td>\n",
       "      <td>grena</td>\n",
       "      <td>cresco3_h144</td>\n",
       "      <td>PFS/porq1_1M/Al_cluster</td>\n",
       "      <td>qe5.0.3_par</td>\n",
       "      <td>DONE</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-12-26 10:29:21</td>\n",
       "      <td>2016-12-26 10:29:28</td>\n",
       "      <td>7</td>\n",
       "      <td>PFS/porq1_1M/Al_clusterqe5.0.3_par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544480</th>\n",
       "      <td>953307</td>\n",
       "      <td>1478885885</td>\n",
       "      <td>1482809980</td>\n",
       "      <td>12</td>\n",
       "      <td>aprea</td>\n",
       "      <td>cresco4_h144</td>\n",
       "      <td></td>\n",
       "      <td>./assembly.sh</td>\n",
       "      <td>EXIT</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-11-11 17:38:05</td>\n",
       "      <td>2016-12-27 03:39:40</td>\n",
       "      <td>3924095</td>\n",
       "      <td>./assembly.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544481</th>\n",
       "      <td>953308</td>\n",
       "      <td>1478885885</td>\n",
       "      <td>1482810053</td>\n",
       "      <td>12</td>\n",
       "      <td>aprea</td>\n",
       "      <td>cresco4_h144</td>\n",
       "      <td></td>\n",
       "      <td>./assembly.sh</td>\n",
       "      <td>EXIT</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-11-11 17:38:05</td>\n",
       "      <td>2016-12-27 03:40:53</td>\n",
       "      <td>3924168</td>\n",
       "      <td>./assembly.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544644</th>\n",
       "      <td>965254</td>\n",
       "      <td>1482834939</td>\n",
       "      <td>1482834945</td>\n",
       "      <td>64</td>\n",
       "      <td>grena</td>\n",
       "      <td>cresco3_h144</td>\n",
       "      <td>PFS/porq1_1M/Al_cluster</td>\n",
       "      <td>qe5.0.3_par</td>\n",
       "      <td>DONE</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-12-27 10:35:39</td>\n",
       "      <td>2016-12-27 10:35:45</td>\n",
       "      <td>6</td>\n",
       "      <td>PFS/porq1_1M/Al_clusterqe5.0.3_par</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         jobid      inizio        fine  numcores   user         queue  \\\n",
       "544642  964821  1482748132  1482748136        64  grena  cresco3_h144   \n",
       "544643  964823  1482748161  1482748168        64  grena  cresco3_h144   \n",
       "544480  953307  1478885885  1482809980        12  aprea  cresco4_h144   \n",
       "544481  953308  1478885885  1482810053        12  aprea  cresco4_h144   \n",
       "544644  965254  1482834939  1482834945        64  grena  cresco3_h144   \n",
       "\n",
       "                      directory     executable jobstatus  numhost  \\\n",
       "544642  PFS/porq1_1M/Al_cluster    qe5.0.3_par      DONE        3   \n",
       "544643  PFS/porq1_1M/Al_cluster    qe5.0.3_par      DONE        3   \n",
       "544480                           ./assembly.sh      EXIT        1   \n",
       "544481                           ./assembly.sh      EXIT        1   \n",
       "544644  PFS/porq1_1M/Al_cluster    qe5.0.3_par      DONE        3   \n",
       "\n",
       "        start_timestamp_py   stop_timestamp_py  duration_py  \\\n",
       "544642 2016-12-26 10:28:52 2016-12-26 10:28:56            4   \n",
       "544643 2016-12-26 10:29:21 2016-12-26 10:29:28            7   \n",
       "544480 2016-11-11 17:38:05 2016-12-27 03:39:40      3924095   \n",
       "544481 2016-11-11 17:38:05 2016-12-27 03:40:53      3924168   \n",
       "544644 2016-12-27 10:35:39 2016-12-27 10:35:45            6   \n",
       "\n",
       "                      executable_full_name  \n",
       "544642  PFS/porq1_1M/Al_clusterqe5.0.3_par  \n",
       "544643  PFS/porq1_1M/Al_clusterqe5.0.3_par  \n",
       "544480                       ./assembly.sh  \n",
       "544481                       ./assembly.sh  \n",
       "544644  PFS/porq1_1M/Al_clusterqe5.0.3_par  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf_gr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read preprocessed lsf_py from initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_py_df = pd.read_excel( os.path.join( Working_dir, \"lsf_v2_py.xlsx\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short comparison of lengths and jobids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538837, 10) (571471, 11)\n"
     ]
    }
   ],
   "source": [
    "print(lsf_py_df.shape, lsf_gr_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571471 529551\n"
     ]
    }
   ],
   "source": [
    "print(lsf_gr_df.jobid.unique().shape[0], lsf_py_df.jobid.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check executable full path names in comparison with the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    540661\n",
      "True      30810\n",
      "Name: executable_full_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(lsf_gr_df.executable_full_name.isin( lsf_py_df.executable_full_name ).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read preprocessed zabbix df and crop new lsf dataset according to zabbix range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zabbix_py_df = pd.read_excel( os.path.join( Working_dir, \"zabbix_v2_py.xlsx\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsf_gr_df = lsf_gr_df.drop(lsf_gr_df[lsf_gr_df.stop_timestamp_py < zabbix_py_df.loc[0, 'timestamp_py']].index &\\\n",
    "                          lsf_gr_df[lsf_gr_df.start_timestamp_py > zabbix_py_df.loc[zabbix_py_df.shape[0]-1, 'timestamp_py']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571471, 14)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsf_gr_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of shortly finished applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_activity_time = lsf_gr_df[lsf_gr_df.duration_py <= 30 ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.619419008138646\n"
     ]
    }
   ],
   "source": [
    "print(short_activity_time/lsf_gr_df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations on the new dataset\n",
    "- The new dataset is larger than the initial one\n",
    "- Names of executables sometimes contain numbers (20, 180, etc) or even timestamp (03:00:00)\n",
    "- If I understood correctly, after regrouping, start time is minimum of the start times of all grouped lines with the same jobid, same for stop time, but it is maximum of all corresponding lines. If we take min-max, we lose data on applications with shorter activity time. Why do we need regrouping?\n",
    "- Should I recalculate everything with this new lsf dataset?\n",
    "- Should I consider jobs <=30 sec duration for each month or for the whole year? I prefer the first, for each month, for consistency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
