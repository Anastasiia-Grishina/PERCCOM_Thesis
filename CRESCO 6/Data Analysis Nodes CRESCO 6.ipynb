{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pytz\n",
    "import datetime\n",
    "from xlsxwriter.workbook import Workbook\n",
    "from xlsxwriter import Workbook\n",
    "import time\n",
    "from scipy import integrate, stats\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Working_dir = os.getcwd()\n",
    "Data_dir = os.path.join(Working_dir, 'Raw data')\n",
    "Data_prep_dir = os.path.join(Working_dir, 'Preprocessed data')\n",
    "Output_dir = os.path.join(Working_dir, 'Analysis')\n",
    "Plots_dir = os.path.join(Output_dir, 'Plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_file_names = ['May2018_idle.csv', 'June2018_idle.csv', 'July2018_idle.csv', \\\n",
    "                    'September2018.csv', 'October2018.csv', 'November2018.csv', \\\n",
    "                    'December2018.csv' , 'January2019.csv']\n",
    "nodes_df_names = [item.split('.')[0] for item in nodes_file_names]\n",
    "nodes_stats_ = 'nodes_stats_'\n",
    "node_df_may = pd.read_csv( os.path.join( Output_dir, nodes_stats_ + 'May2018_idle.csv'), delimiter=\";\", header=0, index_col=0 )\n",
    "node_names = node_df_may.columns.values\n",
    "summary_index = ['total_dcenergy', 'sys_energy', \\\n",
    "                'cpu_energy', 'mem_energy', 'other_energy', \\\n",
    "                'cpu_en_percent', 'mem_en_percent', \\\n",
    "                'other_en_percent', 'sys_util', 'mem_util', 'cpu_util', \\\n",
    "                'other_util','sys_power_max', 'cpu_power_max',\\\n",
    "                'mem_power_max', 'dcenergy_error_percent', \\\n",
    "                'present_in_months', \\\n",
    "                'avg_exh_temp', 'avg_inlet_temp', \\\n",
    "                'avg_cpu1_temp', 'avg_cpu2_temp', \\\n",
    "                'idle_time_sec', 'working_time_sec', \\\n",
    "                'idle_en_integral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_df_dict = {}\n",
    "for file_name, df_name in zip(nodes_file_names, nodes_df_names):\n",
    "    nodes_df_dict[df_name] = pd.read_csv(os.path.join( Output_dir, nodes_stats_ + file_name), \\\n",
    "                                         delimiter=\";\", header=0, index_col=0)\n",
    "    to_drop_ix = np.unique(np.append(\\\n",
    "                                     np.where(nodes_df_dict[df_name].loc['dcenergy_error_percent', :].isna())[0], \\\n",
    "                                     np.where(nodes_df_dict[df_name].loc['dcenergy_error_percent', :] > 5.)[0]))\n",
    "    to_drop = nodes_df_dict[df_name].iloc[:,to_drop_ix].columns.values\n",
    "    nodes_df_dict[df_name].drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_no_drop_df_dict = {}\n",
    "for file_name, df_name in zip(nodes_file_names, nodes_df_names):\n",
    "    nodes_no_drop_df_dict[df_name] = pd.read_csv(os.path.join( Output_dir, nodes_stats_ + file_name), \\\n",
    "                                         delimiter=\";\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_prep_df = {}\n",
    "for file_name, df_name in zip(nodes_file_names, nodes_df_names):\n",
    "    # Read preprocessed data\n",
    "    data_prep_df[df_name] = pd.read_csv( os.path.join( Data_prep_dir, file_name), delimiter=\";\", header=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - all the months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://benalexkeen.com/working-with-timezones-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winter Local Time: 14:00\n",
      "Summer Local Time: 14:00\n",
      "Winter UTC Time: 13:00\n",
      "Summer UTC Time: 12:00\n"
     ]
    }
   ],
   "source": [
    "# winter_dt = datetime.datetime(2017, 1, 1, 14, 0)\n",
    "# print(winter_dt.strftime(\"Winter Local Time: %H:%M\"))\n",
    "\n",
    "# summer_dt = datetime.datetime(2017, 7, 1, 14, 0)\n",
    "# print(summer_dt.strftime(\"Summer Local Time: %H:%M\"))\n",
    "\n",
    "# local_tz = pytz.timezone('Europe/Berlin')\n",
    "# target_tz = pytz.timezone('UTC')\n",
    "\n",
    "# winter_dt = local_tz.localize(winter_dt)\n",
    "# summer_dt = local_tz.localize(summer_dt)\n",
    "\n",
    "# winter_dt = target_tz.normalize(winter_dt)\n",
    "# summer_dt = target_tz.normalize(summer_dt)\n",
    "\n",
    "# print(winter_dt.strftime(\"Winter UTC Time: %H:%M\"))\n",
    "# print(summer_dt.strftime(\"Summer UTC Time: %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmt_converter(x):\n",
    "    fmt_summer = '%a %d %b %H:%M:%S CEST %Y'\n",
    "    fmt_winter = '%a %d %b %H:%M:%S CET %Y'\n",
    "    \n",
    "    datetime_result = datetime.datetime.now()\n",
    "\n",
    "    if 'CEST' in x:\n",
    "        datetime_result = datetime.datetime.strptime(x, fmt_summer)\n",
    "    else: \n",
    "        datetime_result = datetime.datetime.strptime(x, fmt_winter)\n",
    "    return datetime_result\n",
    "\n",
    "def utc_converter(x):\n",
    "    local_tz = pytz.timezone('Europe/Rome')\n",
    "    target_tz = pytz.timezone('UTC')\n",
    "    datetime_init = fmt_converter(x)\n",
    "    datetime_localized = local_tz.localize(datetime_init)\n",
    "    datetime_result = target_tz.normalize(datetime_localized)\n",
    "    return datetime_result\n",
    "\n",
    "def unix_converter(x):\n",
    "    return utc_converter(x).timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for file_name in nodes_file_names:\n",
    "#     node_df = pd.read_csv( os.path.join( Data_dir, file_name), delimiter=\";\", header=0 )\n",
    "#     node_df.dcenergy = node_df.dcenergy.apply(lambda x: float(x.replace(\",\", \".\")) )\n",
    "#     node_df.loc[:,'timestamp_py'] = node_df.tempo.apply(fmt_converter)\n",
    "#     node_df.loc[:,'unix_timestamp'] = node_df.tempo.apply(unix_converter)\n",
    "#     node_df.iloc[:,3:-1] = node_df.iloc[:, 3:-1].\\\n",
    "#         apply(lambda y: y.\\\n",
    "#                 apply(lambda x: \\\n",
    "#                       float(x.replace(\",\", \".\")) if type(x)==str else x ))\n",
    "#     node_df.drop(columns='timestamp_measure', inplace=True)\n",
    "#     # node_df.to_csv(path_or_buf=os.path.join( Data_prep_dir, file_name), sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Energy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def forth_integral(node, time, power=['cpu', 'mem', 'sys']):\n",
    "#     power_kw = node[power + '_power'].values/1000.0\n",
    "#     return(np.dot(power_kw, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forth_integral(y_values, time):\n",
    "    return(np.dot(y_values, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_percentage(a, b):\n",
    "    if a > 0.:\n",
    "        return(abs(a-b) / a * 100.)\n",
    "    else: \n",
    "        return(abs(a-b) / b * 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage(a, b):\n",
    "    return((a / b) * 100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of dataframes to summarize info for every node\n",
    "One dictionary entry = one dataframe = one month $\\ni  \\{$ all nodes - columns $\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create and fill total energy column \n",
    "- total_dcenergy\n",
    "   \n",
    "   energy difference between last and first measurement for every node, since energy meter shows incremental observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df_dict_init = {}\n",
    "for file_name, df_name in zip(nodes_file_names, nodes_df_names):\n",
    "    # Read preprocessed data\n",
    "    node_df = data_prep_df[df_name].copy()\n",
    "    \n",
    "    # Create df\n",
    "    nodes_df_dict_init[df_name] = pd.DataFrame(columns = list(node_df.nodename.unique()), index = [], data=0)\n",
    "    \n",
    "    # Energy meter difference\n",
    "    for node in nodes_df_dict_init[df_name].columns.values:\n",
    "        nodes_df_dict_init[df_name].loc['total_dcenergy', node] = \\\n",
    "            node_df[node_df.nodename == node]['dcenergy'].values[-1] - \\\n",
    "            node_df[node_df.nodename == node]['dcenergy'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate integrals\n",
    "- System, CPU and memory energy use as integral of corresponding power measurements\n",
    "- Portion of CPU, memory and other components in energy use - percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in nodes_df_names[3:4]:\n",
    "    node_df = data_prep_df[df_name].copy()\n",
    "    \n",
    "    for node in nodes_df_dict_init[df_name].columns.values:\n",
    "        one_node_df = node_df[node_df.nodename == node].copy()\n",
    "        \n",
    "        # Read time difference between consecutive measurements and convert from seconds to hours\n",
    "        time_difference = (one_node_df['unix_timestamp'][1:].values -\\\n",
    "            one_node_df['unix_timestamp'][:-1].values)/3600.0\n",
    "\n",
    "        for util_type in ['cpu', 'mem', 'sys']:\n",
    "            # Integrate system power over time\n",
    "            nodes_df_dict_init[df_name].loc[util_type + '_energy', node] = \\\n",
    "                forth_integral(y_values=one_node_df.iloc[1:,:][util_type + '_power'].values/1000.0,\\\n",
    "                               time=time_difference)\n",
    "            \n",
    "#     # Integral of sys power vs dcenergy meter error in %\n",
    "        nodes_df_dict_init[df_name].loc['dcenergy_error_percent', node] = \\\n",
    "            error_percentage(nodes_df_dict_init[df_name].loc['total_dcenergy',node], \\\n",
    "                             nodes_df_dict_init[df_name].loc['sys_energy', node])\n",
    "            \n",
    "    # Energy used for purposes other than CPU and memory\n",
    "    nodes_df_dict_init[df_name].loc['other_energy', :] = nodes_df_dict_init[df_name].loc['sys_energy', :] - \\\n",
    "        nodes_df_dict_init[df_name].loc['cpu_energy', :] - nodes_df_dict_init[df_name].loc['mem_energy', :]\n",
    "    print(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What portion of energy goes for CPU, memory, other components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Energy portion used for CPU and memory in overall the system energy consumption\n",
    "for df_name in nodes_df_names:\n",
    "    for util_type in ['cpu', 'mem', 'other']:\n",
    "        nodes_df_dict_init[df_name].loc[util_type + '_en_percent', :] = \\\n",
    "            percentage(nodes_df_dict_init[df_name].loc[util_type + '_energy',:], \\\n",
    "                       nodes_df_dict_init[df_name].loc['sys_energy', :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Max observed power utilization of CPU, memory and system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df_name in nodes_df_names:\n",
    "    node_df = data_prep_df[df_name].copy()\n",
    "    \n",
    "    for node in nodes_df_dict_init[df_name].columns.values:\n",
    "        one_node_df = node_df[node_df.nodename == node].copy()\n",
    "        \n",
    "        # Find max power utilization by CPU, mem and system\n",
    "        for util_type in ['cpu', 'mem', 'sys']:\n",
    "            max_val = one_node_df.loc[:,util_type + '_power'].max() \n",
    "            nodes_df_dict_init[df_name].loc[util_type + '_power_max', node] = max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Average exhaust, inlet, CPU 1, CPU 2 temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df_name in nodes_df_names:\n",
    "    node_df = data_prep_df[df_name]\n",
    "    \n",
    "    for node in nodes_df_dict_init[df_name].columns.values:\n",
    "        one_node_df = node_df[node_df.nodename == node].copy()\n",
    "        one_node_right_temp_df = one_node_df[(one_node_df.exh_temp>=one_node_df.amb_temp) &\\\n",
    "                                             (one_node_df.exh_temp>0.) & (one_node_df.amb_temp>0.) &\\\n",
    "                                             (one_node_df.cpu1_temp>0.) & (one_node_df.cpu2_temp>0.)].copy()\n",
    "        one_node_right_temp_df.columns = one_node_right_temp_df.columns.str.replace('amb_temp', 'inlet_temp')\n",
    "        for temp_type in ['exh', 'inlet', 'cpu1', 'cpu2']:\n",
    "            nodes_df_dict_init[df_name].loc['avg_'+temp_type+'_temp', node] = one_node_right_temp_df[temp_type+'_temp'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Idle mode\n",
    "$\\leq 200$ kWh of power use is idle mode\n",
    "\n",
    "\n",
    "If sys_power level is registered to be $p^1_{{minus\\;200}}$ for timestamp $t^1$, then it will be assumed that this power level was observed from the previous timestamp $t^0$ until $t^1$\n",
    "- duration\n",
    "- energy integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df_name in nodes_df_names:\n",
    "    node_df = data_prep_df[df_name]\n",
    "    \n",
    "    for node in nodes_df_dict_init[df_name].columns.values:\n",
    "        one_node_df = node_df[node_df.nodename == node].copy()\n",
    "        \n",
    "        idle_sys_power_ix = np.trim_zeros(np.where(one_node_df.sys_power <= 200.)[0]).tolist()\n",
    "        \n",
    "        time_b = one_node_df.iloc[idle_sys_power_ix,:].unix_timestamp\n",
    "        time_a = one_node_df.iloc[[x-1 for x in idle_sys_power_ix],:].unix_timestamp\n",
    "        \n",
    "        nodes_df_dict_init[df_name].loc['idle_time_sec',node] = \\\n",
    "            (time_b.values - time_a.values).sum()\n",
    "            \n",
    "        nodes_df_dict_init[df_name].loc['working_time_sec',node] = \\\n",
    "            one_node_df.unix_timestamp.max() - one_node_df.unix_timestamp.min()\n",
    "            \n",
    "        nodes_df_dict_init[df_name].loc['idle_en_integral',node] = \\\n",
    "            forth_integral( node=one_node_df.iloc[idle_sys_power_ix,:], \\\n",
    "                            time=( time_b.values - time_a.values )/3600., power='sys' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### Branch. Bins of energy levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(0,500,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_name = nodes_df_names[0]\n",
    "\n",
    "node_df = data_prep_df[df_name].copy()\n",
    "\n",
    "for node in nodes_df_dict[df_name].columns.values[:1]:\n",
    "    one_node_df = node_df[node_df.nodename == node].copy()\n",
    "    groups = one_node_df.groupby(pd.cut(one_node_df.sys_power, bins))\n",
    "    \n",
    "energy_level_index = groups.sys_power.sum().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "energy_levels_df_dict = {}\n",
    "\n",
    "for df_name in nodes_df_names:\n",
    "    node_df = data_prep_df[df_name].copy()\n",
    "    energy_levels_df_dict[df_name] = pd.DataFrame(columns = node_names, \\\n",
    "                                                  index = energy_level_index, \\\n",
    "                                                  data=0)\n",
    "\n",
    "    for node in nodes_df_dict[df_name].columns.values:\n",
    "        one_node_df = node_df[node_df.nodename == node].copy()\n",
    "\n",
    "        groups = one_node_df.groupby(pd.cut(one_node_df.sys_power, bins))\n",
    "        energy_levels_df_dict[df_name].loc[:, node] = groups.sys_power.count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_entries_in_total_for_all_months</th>\n",
       "      <th>Percent_entries_in_total_for_all_months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_power</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 50]</th>\n",
       "      <td>783</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(50, 100]</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(100, 150]</th>\n",
       "      <td>1358059</td>\n",
       "      <td>32.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(150, 200]</th>\n",
       "      <td>1467779</td>\n",
       "      <td>34.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 250]</th>\n",
       "      <td>211751</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(250, 300]</th>\n",
       "      <td>994356</td>\n",
       "      <td>23.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(300, 350]</th>\n",
       "      <td>138883</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(350, 400]</th>\n",
       "      <td>28591</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(400, 450]</th>\n",
       "      <td>4802</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            No_entries_in_total_for_all_months  \\\n",
       "sys_power                                        \n",
       "(0, 50]                                    783   \n",
       "(50, 100]                                    0   \n",
       "(100, 150]                             1358059   \n",
       "(150, 200]                             1467779   \n",
       "(200, 250]                              211751   \n",
       "(250, 300]                              994356   \n",
       "(300, 350]                              138883   \n",
       "(350, 400]                               28591   \n",
       "(400, 450]                                4802   \n",
       "\n",
       "            Percent_entries_in_total_for_all_months  \n",
       "sys_power                                            \n",
       "(0, 50]                                        0.02  \n",
       "(50, 100]                                      0.00  \n",
       "(100, 150]                                    32.30  \n",
       "(150, 200]                                    34.91  \n",
       "(200, 250]                                     5.04  \n",
       "(250, 300]                                    23.65  \n",
       "(300, 350]                                     3.30  \n",
       "(350, 400]                                     0.68  \n",
       "(400, 450]                                     0.11  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_idle_energy_summary_df = pd.DataFrame(columns = node_names, index = energy_level_index, data=0)\n",
    "for df_name in nodes_df_names:\n",
    "    en_node_df = energy_levels_df_dict[df_name]\n",
    "    nodes_idle_energy_summary_df = en_node_df.replace([np.inf, -np.inf, np.nan], 0).\\\n",
    "                                        add(nodes_idle_energy_summary_df).fillna(en_node_df)\n",
    "all_entries = nodes_idle_energy_summary_df.sum().sum()\n",
    "nodes_idle_energy_summary_df.loc[:, 'No_entries_in_total_for_all_months'] = nodes_idle_energy_summary_df.sum(axis=1)\n",
    "nodes_idle_energy_summary_df.loc[:, 'Percent_entries_in_total_for_all_months'] = \\\n",
    "    nodes_idle_energy_summary_df.filter(regex=('^cresco6x')).sum(axis=1) / all_entries * 100.\n",
    "\n",
    "nodes_idle_energy_summary_df.Percent_entries_in_total_for_all_months = \\\n",
    "    nodes_idle_energy_summary_df.Percent_entries_in_total_for_all_months.round(2)\n",
    "nodes_idle_energy_summary_df.to_csv( path_or_buf=os.path.join( Output_dir, 'nodes_idle_energy_summary.csv' ), sep=';' )\n",
    "nodes_idle_energy_summary_df.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_dcenergy_MWh</th>\n",
       "      <th>total_sys_energy_MWh</th>\n",
       "      <th>idle_energy_MWh</th>\n",
       "      <th>idle_energy_percent_MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>May2018_idle</th>\n",
       "      <td>14.693</td>\n",
       "      <td>15.761</td>\n",
       "      <td>14.542</td>\n",
       "      <td>92.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June2018_idle</th>\n",
       "      <td>24.173</td>\n",
       "      <td>27.456</td>\n",
       "      <td>25.584</td>\n",
       "      <td>93.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July2018_idle</th>\n",
       "      <td>21.624</td>\n",
       "      <td>24.611</td>\n",
       "      <td>21.279</td>\n",
       "      <td>86.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September2018</th>\n",
       "      <td>22.969</td>\n",
       "      <td>25.461</td>\n",
       "      <td>17.674</td>\n",
       "      <td>69.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October2018</th>\n",
       "      <td>27.048</td>\n",
       "      <td>32.490</td>\n",
       "      <td>12.853</td>\n",
       "      <td>39.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November2018</th>\n",
       "      <td>26.540</td>\n",
       "      <td>31.381</td>\n",
       "      <td>13.149</td>\n",
       "      <td>41.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December2018</th>\n",
       "      <td>33.023</td>\n",
       "      <td>37.567</td>\n",
       "      <td>7.881</td>\n",
       "      <td>20.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January2019</th>\n",
       "      <td>19.393</td>\n",
       "      <td>21.489</td>\n",
       "      <td>9.386</td>\n",
       "      <td>43.675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               total_dcenergy_MWh  total_sys_energy_MWh  idle_energy_MWh  \\\n",
       "May2018_idle               14.693                15.761           14.542   \n",
       "June2018_idle              24.173                27.456           25.584   \n",
       "July2018_idle              21.624                24.611           21.279   \n",
       "September2018              22.969                25.461           17.674   \n",
       "October2018                27.048                32.490           12.853   \n",
       "November2018               26.540                31.381           13.149   \n",
       "December2018               33.023                37.567            7.881   \n",
       "January2019                19.393                21.489            9.386   \n",
       "\n",
       "               idle_energy_percent_MWh  \n",
       "May2018_idle                    92.266  \n",
       "June2018_idle                   93.182  \n",
       "July2018_idle                   86.460  \n",
       "September2018                   69.415  \n",
       "October2018                     39.559  \n",
       "November2018                    41.900  \n",
       "December2018                    20.980  \n",
       "January2019                     43.675  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_by_month = pd.DataFrame(data=0, index=nodes_df_names, columns=['total_dcenergy_MWh', 'total_sys_energy_MWh'])\n",
    "\n",
    "for df_name in nodes_df_names:\n",
    "    energy_by_month.loc[df_name, 'total_dcenergy_MWh'] = nodes_df_dict[df_name].loc['total_dcenergy', :].sum()\n",
    "    energy_by_month.loc[df_name, 'total_sys_energy_MWh'] = nodes_no_drop_df_dict[df_name].loc['sys_energy', :].sum()\n",
    "    energy_by_month.loc[df_name, 'idle_energy_MWh'] = nodes_no_drop_df_dict[df_name].loc['idle_en_integral', :].sum()\n",
    "\n",
    "energy_by_month = energy_by_month/1000.\n",
    "\n",
    "energy_by_month.loc[:, 'idle_energy_percent_MWh'] = energy_by_month.idle_energy_MWh / \\\n",
    "                                                                energy_by_month.total_sys_energy_MWh * 100.\n",
    "energy_by_month = energy_by_month.round(3)\n",
    "energy_by_month.to_csv( path_or_buf=os.path.join( Output_dir, 'energy_summary_by_month.csv' ), sep=';')\n",
    "energy_by_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Branch finished\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. System air flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df_name in nodes_df_names:\n",
    "    node_df = data_prep_df[df_name]\n",
    "    \n",
    "    for node in nodes_no_drop_df_dict[df_name].columns.values:\n",
    "        one_node_df = node_df[node_df.nodename == node].copy()\n",
    "        \n",
    "        # Read time difference between consecutive measurements \n",
    "        # and convert from seconds to minutes\n",
    "        time_difference = (one_node_df['unix_timestamp'][1:].values -\\\n",
    "            one_node_df['unix_timestamp'][:-1].values) / 60.0\n",
    "        \n",
    "        nodes_no_drop_df_dict[df_name].loc['sys_air_flow_CFM', node] = \\\n",
    "            forth_integral(y_values=one_node_df.iloc[1:,:]['sysairflow'].values, \\\n",
    "                           time=time_difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -1. Save stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nodes_df_dict_init\n",
    "for file_name, df_name in zip(nodes_file_names, nodes_df_names):\n",
    "    nodes_no_drop_df_dict[df_name].to_csv( path_or_buf=os.path.join( Output_dir, nodes_stats_ + file_name), sep=';' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### All calculations for nodes stats in one loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aagri\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May2018_idle\n",
      "June2018_idle\n",
      "July2018_idle\n",
      "September2018\n",
      "October2018\n",
      "November2018\n",
      "December2018\n",
      "January2019\n"
     ]
    }
   ],
   "source": [
    "nodes_df_dict_init = {}\n",
    "data_prep_df       = {}\n",
    "\n",
    "for file_name, df_name in zip(nodes_file_names, nodes_df_names):\n",
    "    \n",
    "    data_prep_df[df_name]       = pd.read_csv( os.path.join( Data_prep_dir, file_name), delimiter=\";\", header=0 )\n",
    "    node_df                     = data_prep_df[df_name].copy()\n",
    "    nodes_df_dict_init[df_name] = pd.DataFrame(columns = list(node_df.nodename.unique()), \\\n",
    "                                               index = ['total_dcenergy', 'sys_energy', \\\n",
    "                                                        'cpu_energy', 'mem_energy', 'other_energy', \\\n",
    "                                                        'cpu_en_percent', 'mem_en_percent', \\\n",
    "                                                        'other_en_percent', 'sys_util', 'mem_util', 'cpu_util', \\\n",
    "                                                        'other_util','sys_power_max', 'cpu_power_max',\\\n",
    "                                                        'mem_power_max', 'dcenergy_error_percent'], \n",
    "                                               data = 0)\n",
    "    \n",
    "    for node in nodes_df_dict_init[df_name].columns.values:\n",
    "        one_node_df = node_df[node_df.nodename == node].copy()\n",
    "        \n",
    "        # Time difference for power integral\n",
    "        time_difference = (one_node_df['unix_timestamp'][1:].values -\\\n",
    "            one_node_df['unix_timestamp'][:-1].values)/3600.0\n",
    "\n",
    "        for util_type in ['cpu', 'mem', 'sys']:\n",
    "            # Integrate system power over time\n",
    "            nodes_df_dict_init[df_name].loc[util_type + '_energy', node] = \\\n",
    "                forth_integral(y_values=one_node_df.iloc[1:,:][util_type + '_power'].values/1000.0,\\\n",
    "                               time=time_difference)\n",
    "#                 forth_integral(node=one_node_df.iloc[1:,:], time=time_difference), power=util_type)\n",
    "\n",
    "\n",
    "            # Find max power utilization by CPU, mem and system\n",
    "            max_val = one_node_df.loc[:,util_type + '_power'].max() \n",
    "            if nodes_df_dict_init[df_name].loc[util_type + '_power_max', node] < max_val:\n",
    "                nodes_df_dict_init[df_name].loc[util_type + '_power_max', node] = max_val\n",
    "        \n",
    "        # Energy meter increase\n",
    "        nodes_df_dict_init[df_name].loc['total_dcenergy', node] = \\\n",
    "            node_df[node_df.nodename == node]['dcenergy'].values[-1] - \\\n",
    "            node_df[node_df.nodename == node]['dcenergy'].values[0]\n",
    "    \n",
    "        # Integral of sys power vs dcenergy meter error in %\n",
    "        nodes_df_dict_init[df_name].loc['dcenergy_error_percent', node] = \\\n",
    "            error_percentage(nodes_df_dict_init[df_name].loc['total_dcenergy',node], \\\n",
    "                             nodes_df_dict_init[df_name].loc['sys_energy', node])\n",
    "            \n",
    "        # Average exhaust, inlet, CPU 1, CPU 2 temperature\n",
    "        one_node_right_temp_df = one_node_df[(one_node_df.exh_temp>=one_node_df.amb_temp) &\\\n",
    "                                             (one_node_df.exh_temp>0.) & (one_node_df.amb_temp>0.) &\\\n",
    "                                             (one_node_df.cpu1_temp>0.) & (one_node_df.cpu2_temp>0.)].copy()\n",
    "        one_node_right_temp_df.columns = one_node_right_temp_df.columns.str.replace('amb_temp', 'inlet_temp')\n",
    "        for temp_type in ['exh', 'inlet', 'cpu1', 'cpu2']:\n",
    "            nodes_df_dict_init[df_name].loc['avg_'+temp_type+'_temp', node] = one_node_right_temp_df[temp_type+'_temp'].mean()\n",
    "            \n",
    "        # Idle stats\n",
    "        idle_sys_power_ix = np.trim_zeros(np.where(one_node_df.sys_power <= 200.)[0]).tolist()\n",
    "        \n",
    "        time_b = one_node_df.iloc[idle_sys_power_ix,:].unix_timestamp\n",
    "        time_a = one_node_df.iloc[[x-1 for x in idle_sys_power_ix],:].unix_timestamp\n",
    "        \n",
    "        nodes_df_dict_init[df_name].loc['idle_time_sec',node] = \\\n",
    "            (time_b.values - time_a.values).sum()\n",
    "            \n",
    "        nodes_df_dict_init[df_name].loc['working_time_sec',node] = \\\n",
    "            one_node_df.unix_timestamp.max() - one_node_df.unix_timestamp.min()\n",
    "            \n",
    "        nodes_df_dict_init[df_name].loc['idle_en_integral',node] = \\\n",
    "            forth_integral( y_values=one_node_df.iloc[idle_sys_power_ix,:].values/1000.0, \\#node=one_node_df.iloc[idle_sys_power_ix,:], \\\n",
    "                            time=( time_b.values - time_a.values )/3600., power='sys' )\n",
    "            \n",
    "    # Energy used for purposes other than CPU and memory\n",
    "    nodes_df_dict_init[df_name].loc['other_energy', :] = nodes_df_dict_init[df_name].loc['sys_energy', :] - \\\n",
    "        nodes_df_dict_init[df_name].loc['cpu_energy', :] - nodes_df_dict_init[df_name].loc['mem_energy', :]\n",
    "        \n",
    "    # Energy portion used for CPU and memory in overall the system energy consumption\n",
    "    for util_type in ['cpu', 'mem', 'other']:\n",
    "        nodes_df_dict_init[df_name].loc[util_type + '_en_percent', :] = \\\n",
    "            percentage(nodes_df_dict_init[df_name].loc[util_type + '_energy',:], \\\n",
    "                       nodes_df_dict_init[df_name].loc['sys_energy', :])\n",
    "    # Save\n",
    "    nodes_df_dict_init[df_name].to_csv( path_or_buf=os.path.join( Output_dir, nodes_stats_ + file_name), sep=';' )    \n",
    "    print(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Summary for all nodes over all months\n",
    "- Resultant dataframe is self-descriptive by its row names\n",
    "- Each column corresponds to one node characterized by its name\n",
    "- Last two columns are added for average or total summation over all nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows_to_calc_sum = ['total_dcenergy', 'sys_energy', 'cpu_energy', 'mem_energy', 'other_energy', 'idle_en_integral']\n",
    "rows_to_calc_avg = ['cpu_en_percent', 'mem_en_percent', \\\n",
    "                    'other_en_percent', 'sys_power_max', 'cpu_power_max',\\\n",
    "                    'mem_power_max', 'dcenergy_error_percent',\\\n",
    "                    'sys_util', 'mem_util', 'cpu_util', 'other_util', \\\n",
    "                    'avg_exh_temp', 'avg_inlet_temp', \\\n",
    "                    'avg_cpu1_temp', 'avg_cpu2_temp', \\\n",
    "                    'idle_time_sec', 'working_time_sec']\n",
    "rows_en_percent = ['cpu_en_percent', 'mem_en_percent']\n",
    "\n",
    "nodes_summary_df = pd.DataFrame(columns = node_names, index = summary_index, data=0)\n",
    "\n",
    "nodes_summary_no_drop_df = nodes_summary_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df_name in nodes_df_names:\n",
    "    node_df = nodes_no_drop_df_dict[df_name].copy()\n",
    "    \n",
    "    # Drop columns where the relative error between \n",
    "    # dcenergy and system power integral is high\n",
    "    to_drop_ix = np.unique(np.append(\\\n",
    "                                     np.where(node_df.loc['dcenergy_error_percent', :].isna())[0], \\\n",
    "                                     np.where(node_df.loc['dcenergy_error_percent', :] > 5.)[0]))\n",
    "    to_drop = node_df.iloc[:,to_drop_ix].columns.values\n",
    "    \n",
    "    # Add counter of node presence in months to further count average\n",
    "    node_df.loc['present_in_months', :] = 1\n",
    "    \n",
    "    # Fill summary with and without columns to drop: dcenergy based and sys_power integral based datasets\n",
    "    nodes_summary_no_drop_df = node_df.replace([np.inf, -np.inf, np.nan], 0).add(nodes_summary_no_drop_df).fillna(node_df)\n",
    "    \n",
    "    node_df.loc[:,to_drop] = 0\n",
    "    nodes_summary_df = node_df.add(nodes_summary_df).fillna(node_df)\n",
    "    \n",
    "nodes_summary_no_drop_df.loc['total_dcenergy', :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calc total and avg over all nodes for summary dfs\n",
    "def summary_calc(df):\n",
    "    df.loc[:,'total_all_nodes'] = df.loc[rows_to_calc_sum,:].sum(axis=1)\n",
    "    df.loc[:,'total_all_nodes'].fillna(0, inplace=True)\n",
    "\n",
    "    df.loc[rows_to_calc_avg,:'cresco6x216'] = df.loc[rows_to_calc_avg,:'cresco6x216'] / \\\n",
    "                                                                df.loc['present_in_months',:'cresco6x216']\n",
    "    df.loc[:,'avg_all_nodes']  = df.loc[rows_to_calc_avg,:'cresco6x216'].mean(axis=1)\n",
    "    df.loc['other_en_percent','avg_all_nodes'] = 100.0 - df.loc[rows_en_percent,'avg_all_nodes'].sum()\n",
    "    df.loc[:,'avg_all_nodes'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_calc(nodes_summary_df)\n",
    "summary_calc(nodes_summary_no_drop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_summary_df.to_csv(path_or_buf=os.path.join( Output_dir, 'nodes_summary_all_months.csv'), sep=\";\")\n",
    "nodes_summary_no_drop_df.to_csv(path_or_buf=os.path.join( Output_dir, 'nodes_summary_all_months_no_drop.csv'), sep=\";\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Availability of energy and system power data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_summary_df = pd.read_csv(os.path.join( Output_dir, 'nodes_summary_all_months.csv'), \\\n",
    "                               delimiter=\";\", header=0, index_col=0)\n",
    "nodes_summary_no_drop_df = pd.read_csv(os.path.join( Output_dir, 'nodes_summary_all_months_no_drop.csv'), \\\n",
    "                                delimiter=\";\", header=0, index_col=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average of the relative error between integral of system power and energy meter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6585077240383141"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_summary_df.loc['dcenergy_error_percent', :].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information of sys_power present for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dcenergy_present</th>\n",
       "      <th>sys_power_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>May2018_idle</th>\n",
       "      <td>198</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June2018_idle</th>\n",
       "      <td>188</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July2018_idle</th>\n",
       "      <td>187</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September2018</th>\n",
       "      <td>192</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October2018</th>\n",
       "      <td>178</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November2018</th>\n",
       "      <td>180</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December2018</th>\n",
       "      <td>186</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January2019</th>\n",
       "      <td>193</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dcenergy_present  sys_power_present\n",
       "May2018_idle                198                214\n",
       "June2018_idle               188                214\n",
       "July2018_idle               187                214\n",
       "September2018               192                214\n",
       "October2018                 178                214\n",
       "November2018                180                213\n",
       "December2018                186                213\n",
       "January2019                 193                213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_by_month = pd.DataFrame(data=0, index=nodes_df_names, columns=['dcenergy_present', 'sys_power_present'])\n",
    "\n",
    "for df_name in nodes_df_names:\n",
    "    month_df = nodes_no_drop_df_dict[df_name].filter(regex=('energy'), axis=0)\n",
    "    analysis_by_month.loc[df_name, 'dcenergy_present'] = nodes_df_dict[df_name].shape[1]\n",
    "    analysis_by_month.loc[df_name, 'sys_power_present'] = len(month_df.columns.values) - month_df.loc[:, month_df.isna().any()].shape[1]\n",
    "analysis_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187.75, 213.625)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_by_month.dcenergy_present.mean(), analysis_by_month.sys_power_present.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percent of energy measurements close to sys_power integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.4074074074074 91.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# Check if the nodes excluded because of sys_power missing data are present in dataset working with dcenergy\n",
    "for df_name in nodes_df_names:\n",
    "    month_df = nodes_no_drop_df_dict[df_name].filter(regex=('energy'), axis=0)\n",
    "    nan_cols_sys_energy = month_df.loc[:, month_df.isna().any()].columns.values\n",
    "    for col in nan_cols_sys_energy:\n",
    "        if col in nodes_df_dict[df_name].columns.values:\n",
    "            print(df_name,  month_df.loc[:, month_df.isna().any()].columns.values )\n",
    "            \n",
    "print(analysis_by_month.dcenergy_present.min()/216.*100, analysis_by_month.dcenergy_present.max()/216.*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Errors in DC energy meter over months concern the following nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcenergy_error_nodes_dict = {}\n",
    "dcenergy_all_error_nodes = []\n",
    "for file_name, df_name in zip(nodes_file_names, nodes_df_names):\n",
    "    dcenergy_error_nodes_dict[df_name] = np.where(nodes_no_drop_df_dict[df_name].loc[\"dcenergy_error_percent\", :] > 5.)[0]\n",
    "    \n",
    "    node_df = data_prep_df[df_name]\n",
    "    \n",
    "    for node in nodes_no_drop_df_dict[df_name].iloc[:, dcenergy_error_nodes_dict[df_name] ].columns.values:\n",
    "        int_name = int(node.split('x')[-1])\n",
    "        if not(int_name in dcenergy_all_error_nodes):\n",
    "            dcenergy_all_error_nodes.append(int_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 47, 52, 53, 54, 55, 58, 59, 60, 61, 64, 65, 66, 67, 68, 71, 72, 73, 77, 78, 79, 82, 83, 91, 92, 93, 94, 96, 98, 100, 101, 102, 105, 107, 108, 112, 115, 117, 118, 119, 120, 121, 124, 127, 131, 134, 135, 137, 139, 140, 141, 146, 150, 151, 154, 158, 160, 162, 163, 164, 169, 170, 172, 173, 175, 176, 177, 179, 181, 182, 187, 191, 195, 197, 198, 203, 204, 206, 208, 210, 211, 213, 215, 216]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(dcenergy_all_error_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join( Output_dir,'dcenergy_error_nodes.txt'), \"w\") as f:\n",
    "    f.write(str(list(set(dcenergy_all_error_nodes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join( Output_dir,'dcenergy_error_nodes.csv'),'w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(dcenergy_error_nodes_dict.keys(), dcenergy_error_nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "plt.ioff()\n",
    "for file_name, df_name in zip(nodes_file_names, nodes_df_names):\n",
    "    nodes_stats = nodes_no_drop_df_dict[df_name]\n",
    "    node_df     = data_prep_df[df_name]\n",
    "    for node in nodes_stats.iloc[:, dcenergy_error_nodes_dict[df_name]].columns.values:\n",
    "        int_name = int(node.split('x')[-1])\n",
    "        fig = node_df[node_df.nodename == node].\\\n",
    "            plot(x='timestamp_py', y='dcenergy', title=df_name+'\\nNode '+str(int_name)+' dc_energy').get_figure()\n",
    "        fig.savefig( os.path.join( Plots_dir, 'Error dcenergy', 'Error_dc_en_' + df_name + '_' + node + '.png' ), dpi=500 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "## Max CPU, system and memory power utilization of nodes over all months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_max_power = pd.DataFrame(columns = node_names, \\\n",
    "                              index = ['cpu_power_max', 'mem_power_max', 'sys_power_max'], \\\n",
    "                              data=0)\n",
    "for file_name in nodes_file_names:\n",
    "    nodes_stats = pd.read_csv( os.path.join( Output_dir, nodes_stats_+file_name), \\\n",
    "                              delimiter=\";\", header=0, index_col=0 )\n",
    "    for node in node_names:\n",
    "        for util_type in ['cpu', 'mem', 'sys']:\n",
    "            max_val = nodes_stats.loc[util_type + '_power_max', node]\n",
    "            if node_max_power.loc[util_type + '_power_max', node] < max_val:\n",
    "                node_max_power.loc[util_type + '_power_max', node] = max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_max_power.to_csv( path_or_buf=os.path.join( Output_dir, 'node_max_power_all_months.csv'), sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cresco6x001</th>\n",
       "      <th>cresco6x002</th>\n",
       "      <th>cresco6x003</th>\n",
       "      <th>cresco6x004</th>\n",
       "      <th>cresco6x005</th>\n",
       "      <th>cresco6x006</th>\n",
       "      <th>cresco6x007</th>\n",
       "      <th>cresco6x008</th>\n",
       "      <th>cresco6x009</th>\n",
       "      <th>cresco6x010</th>\n",
       "      <th>...</th>\n",
       "      <th>cresco6x207</th>\n",
       "      <th>cresco6x208</th>\n",
       "      <th>cresco6x209</th>\n",
       "      <th>cresco6x210</th>\n",
       "      <th>cresco6x211</th>\n",
       "      <th>cresco6x212</th>\n",
       "      <th>cresco6x213</th>\n",
       "      <th>cresco6x214</th>\n",
       "      <th>cresco6x215</th>\n",
       "      <th>cresco6x216</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cpu_power_max</th>\n",
       "      <td>270.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>350.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mem_power_max</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_power_max</th>\n",
       "      <td>350.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>...</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cresco6x001  cresco6x002  cresco6x003  cresco6x004  \\\n",
       "cpu_power_max        270.0        290.0        290.0        320.0   \n",
       "mem_power_max         44.0         44.0         43.0         42.0   \n",
       "sys_power_max        350.0        360.0        360.0        360.0   \n",
       "\n",
       "               cresco6x005  cresco6x006  cresco6x007  cresco6x008  \\\n",
       "cpu_power_max        280.0        340.0        340.0        340.0   \n",
       "mem_power_max         44.0         44.0         44.0         45.0   \n",
       "sys_power_max        340.0        430.0        430.0        430.0   \n",
       "\n",
       "               cresco6x009  cresco6x010     ...       cresco6x207  \\\n",
       "cpu_power_max        340.0        350.0     ...             350.0   \n",
       "mem_power_max         41.0         44.0     ...              45.0   \n",
       "sys_power_max        440.0        430.0     ...             440.0   \n",
       "\n",
       "               cresco6x208  cresco6x209  cresco6x210  cresco6x211  \\\n",
       "cpu_power_max        340.0        340.0        340.0        340.0   \n",
       "mem_power_max         45.0         43.0         46.0         42.0   \n",
       "sys_power_max        440.0        440.0        440.0        430.0   \n",
       "\n",
       "               cresco6x212  cresco6x213  cresco6x214  cresco6x215  cresco6x216  \n",
       "cpu_power_max        350.0        340.0        340.0        270.0        250.0  \n",
       "mem_power_max         44.0         47.0         42.0         18.0         27.0  \n",
       "sys_power_max        440.0        440.0        430.0        320.0        300.0  \n",
       "\n",
       "[3 rows x 215 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_max_power = pd.read_csv( os.path.join( Output_dir, 'node_max_power_all_months.csv'), \\\n",
    "                              delimiter=\";\", header=0, index_col=0 )\n",
    "node_max_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max system power use observed: \t 450.0 \n",
      "Max CPU power use observed: \t 350.0 \n",
      "Max memory power use observed: \t 255.0\n"
     ]
    }
   ],
   "source": [
    "print('Max system power use observed: \\t', node_max_power.loc['sys_power_max',:].max(), \\\n",
    "      '\\nMax CPU power use observed: \\t', node_max_power.loc['cpu_power_max',:].max(), \\\n",
    "      '\\nMax memory power use observed: \\t', node_max_power.loc['mem_power_max',:].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Correlation between temperature and power utilization or load\n",
    "### Temperature, fans speed and CPU power trends - September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df_name in nodes_df_names:\n",
    "    year = re.findall(r'\\d+', df_name)[0]\n",
    "    month = df_name.split(year)[0]\n",
    "    plot_energy_cons(data=nodes_df_dict[df_name].iloc[5:8,:].mean(axis=1), \\\n",
    "                     node='', \\\n",
    "                     month=month, year=year, avg_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_stats_Sept = pd.read_csv(os.path.join( Output_dir, nodes_stats_ + 'September2018.csv'), \\\n",
    "                                         delimiter=\";\", header=0, index_col=0)\n",
    "to_drop_ix = np.unique(np.append(\\\n",
    "                                     np.where(nodes_stats_Sept.loc[\"dcenergy_error_percent\", :].isna())[0], \\\n",
    "                                     np.where(nodes_stats_Sept.loc[\"dcenergy_error_percent\", :] > 5.)[0]))\n",
    "to_drop = nodes_stats_Sept.iloc[:,to_drop_ix].columns.values\n",
    "node_df_Sept = pd.read_csv(os.path.join( Data_prep_dir, 'September2018.csv'), \\\n",
    "                                         delimiter=\";\", header=0)\n",
    "for node in to_drop:\n",
    "    node_df_Sept.drop(index=node_df_Sept[node_df_Sept.nodename == node].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_Sept_norm = node_df_Sept[node_df_Sept.nodename == node_df_Sept.nodename.unique()[0]].copy()\n",
    "\n",
    "node_Sept_norm.loc[:, ['cpu_power', 'cpu1_temp', 'cpu2_temp', 'exh_temp']] = \\\n",
    "    preprocessing.normalize(node_Sept_norm.loc[:, ['cpu_power','cpu1_temp', 'cpu2_temp', 'exh_temp']], norm='max', axis=0)\n",
    "node_Sept_norm.exh_temp = round(node_Sept_norm.exh_temp, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.3486975817138365, pvalue=0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(a=node_df_Sept.exh_temp.values, b=node_df_Sept.cpu_power.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.39054727848038256, 1.6573117150516118e-110) (0.4455773885153568, 4.1237857999012705e-147) (0.2811746778478721, 6.179197441727707e-56)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(node_Sept_norm.cpu_power, node_Sept_norm.cpu1_temp), \\\n",
    "      stats.pearsonr(node_Sept_norm.cpu_power, node_Sept_norm.cpu2_temp), \\\n",
    "      stats.pearsonr(node_Sept_norm.cpu_power, node_Sept_norm.exh_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2811746778478721, 6.179197441727707e-56)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(node_Sept_norm.cpu_power, node_Sept_norm.exh_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further analysis\n",
    "- normalize and correlate fans and CPU power ranges\n",
    "- investigate on temperature fluctuations\n",
    "- think of how to work with all the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for filename in nodes_file_names: \n",
    "#     dst = 'nodes_stats_' + filename\n",
    "#     src = 'new_nodes_stats_' + filename\n",
    "\n",
    "#     # rename() function will \n",
    "#     # rename all the files \n",
    "#     os.rename(os.path.join( Output_dir, src ), os.path.join( Output_dir, dst )) \n",
    "\n",
    "# src = 'new_nodes_summary_all_months.csv'\n",
    "# dst = 'nodes_summary_all_months.csv'\n",
    "# os.rename(os.path.join( Output_dir, src ), os.path.join( Output_dir, dst ))\n",
    "\n",
    "# src = 'new_nodes_summary_all_months_no_drop.csv'\n",
    "# dst = 'nodes_summary_all_months_no_drop.csv'\n",
    "# os.rename(os.path.join( Output_dir, src ), os.path.join( Output_dir, dst )) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
